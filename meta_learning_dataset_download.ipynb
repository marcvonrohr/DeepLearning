{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcvonrohr/DeepLearning/blob/main/meta_learning_dataset_download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "54242527",
      "metadata": {
        "id": "54242527",
        "outputId": "04845d9f-f1aa-4943-def2-cddef6863568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting Google Drive...\n",
            "Mounted at /content/drive\n",
            "...Google Drive connected.\n",
            "Archive directory (storage): /content/drive/MyDrive/Deep Learning/datasets/inaturalist/archives\n",
            "Extracted directory (browsing): /content/drive/MyDrive/Deep Learning/datasets/inaturalist/extracted\n",
            "Temporary VM workspace created at: /content/data_temp\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Mount Google Drive ---\n",
        "print(\"Connecting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"...Google Drive connected.\")\n",
        "\n",
        "# --- 2. Define All Google Drive Paths ---\n",
        "GDRIVE_ROOT = '/content/drive/MyDrive/'\n",
        "PROJECT_DIR = os.path.join(GDRIVE_ROOT, 'Deep Learning')\n",
        "DATASETS_ROOT_DIR = os.path.join(PROJECT_DIR, 'datasets')\n",
        "INAT_ROOT_DIR = os.path.join(DATASETS_ROOT_DIR, 'inaturalist')\n",
        "\n",
        "# Folder for the COMPRESSED .tar.gz files\n",
        "ARCHIVES_DIR = os.path.join(INAT_ROOT_DIR, 'archives')\n",
        "# Folder for the EXTRACTED browseable files\n",
        "EXTRACTED_DIR_ON_DRIVE = os.path.join(INAT_ROOT_DIR, 'extracted')\n",
        "\n",
        "# Create all necessary GDrive directories\n",
        "os.makedirs(ARCHIVES_DIR, exist_ok=True)\n",
        "os.makedirs(EXTRACTED_DIR_ON_DRIVE, exist_ok=True)\n",
        "\n",
        "print(f\"Archive directory (storage): {ARCHIVES_DIR}\")\n",
        "print(f\"Extracted directory (browsing): {EXTRACTED_DIR_ON_DRIVE}\")\n",
        "\n",
        "# --- 3. Define Local VM Paths (Temporary Workspace) ---\n",
        "LOCAL_DATA_ROOT = '/content/data_temp'\n",
        "LOCAL_TAR_FILE = os.path.join(LOCAL_DATA_ROOT, 'temp.tar.gz')\n",
        "LOCAL_UNPACK_DIR = os.path.join(LOCAL_DATA_ROOT, 'unpacked')\n",
        "\n",
        "# Create local VM directories\n",
        "os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
        "os.makedirs(LOCAL_UNPACK_DIR, exist_ok=True)\n",
        "print(f\"Temporary VM workspace created at: {LOCAL_DATA_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  PHASE 1: DOWNLOAD ARCHIVES TO GDRIVE\n",
        "#################################################################\n",
        "print(\"\\n--- PHASE 1: Downloading Archives to Google Drive ---\")\n",
        "\n",
        "# --- 1a. Define Download URLs and Target Paths ---\n",
        "urls = {\n",
        "    \"2021_train_mini\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz\",\n",
        "    \"2021_valid\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz\"\n",
        "}\n",
        "\n",
        "files_to_download = {\n",
        "    \"2021_train_mini\": os.path.join(ARCHIVES_DIR, '2021_train_mini.tar.gz'),\n",
        "    \"2021_valid\": os.path.join(ARCHIVES_DIR, '2021_valid.tar.gz')\n",
        "}\n",
        "\n",
        "# --- 1b. Download Files using wget ---\n",
        "for name, path in files_to_download.items():\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"\\nDownloading '{name}.tar.gz'...\")\n",
        "        print(f\"Source: {urls[name]}\")\n",
        "        print(f\"Destination: {path}\")\n",
        "        print(\"This may take a long time. Colab Pro session recommended.\")\n",
        "        !wget -O \"{path}\" \"{urls[name]}\"\n",
        "        print(f\"...Download '{name}' complete.\")\n",
        "    else:\n",
        "        print(f\"'{name}.tar.gz' already found at {path}. Skipping download.\")\n",
        "\n",
        "print(\"\\n--- PHASE 1 Complete: Archives are on Google Drive. ---\")\n",
        "!ls -lh \"$ARCHIVES_DIR\""
      ],
      "metadata": {
        "id": "idES9v790FMM"
      },
      "id": "idES9v790FMM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  PHASE 2: UNPACK ARCHIVES TO GDRIVE (using VM as temp)\n",
        "#################################################################\n",
        "print(\"\\n--- PHASE 2: Unpacking Archives to GDrive (for browsing) ---\")\n",
        "print(\"This phase uses the local VM for fast unpacking.\")\n",
        "\n",
        "# --- 2a. List of files to process ---\n",
        "files_to_process = {\n",
        "    \"2021_train_mini\": {\n",
        "        \"archive_path\": files_to_download[\"2021_train_mini\"],\n",
        "        \"final_check_path\": os.path.join(EXTRACTED_DIR_ON_DRIVE, '2021_train_mini')\n",
        "    },\n",
        "    \"2021_valid\": {\n",
        "        \"archive_path\": files_to_download[\"2021_valid\"],\n",
        "        \"final_check_path\": os.path.join(EXTRACTED_DIR_ON_DRIVE, '2021_valid')\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- 2b. Process each file ---\n",
        "for name, paths in files_to_process.items():\n",
        "    print(f\"\\n--- Processing {name} ---\")\n",
        "\n",
        "    # Check if it's already done\n",
        "    if os.path.exists(paths[\"final_check_path\"]):\n",
        "        print(f\"'{name}' already exists in GDrive 'extracted' folder. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Copy archive from GDrive to local VM (Fast)\n",
        "    print(f\"Copying '{name}.tar.gz' from Drive to local VM...\")\n",
        "    start_time = time.time()\n",
        "    !cp \"{paths['archive_path']}\" \"{LOCAL_TAR_FILE}\"\n",
        "    print(f\"...Copy complete. Took {time.time() - start_time:.2f}s.\")\n",
        "\n",
        "    # Unpack locally on VM (Fast)\n",
        "    print(f\"Unpacking '{name}' on local VM...\")\n",
        "    start_time = time.time()\n",
        "    !tar -xzf \"{LOCAL_TAR_FILE}\" -C \"{LOCAL_UNPACK_DIR}\"\n",
        "    print(f\"...Unpack complete. Took {time.time() - start_time:.2f}s.\")\n",
        "\n",
        "    # Identify the folder name (e.g., '2021_train_mini')\n",
        "    unpacked_folder_name = os.listdir(LOCAL_UNPACK_DIR)[0]\n",
        "    local_path_to_copy = os.path.join(LOCAL_UNPACK_DIR, unpacked_folder_name)\n",
        "\n",
        "    # Copy the *unpacked folder* from VM back to GDrive (Slow)\n",
        "    print(f\"Copying unpacked folder '{unpacked_folder_name}' from VM to GDrive...\")\n",
        "    print(\"WARNING: This will take MANY HOURS for 'train_mini'.\")\n",
        "    start_time = time.time()\n",
        "    !cp -r \"{local_path_to_copy}\" \"{EXTRACTED_DIR_ON_DRIVE}\"\n",
        "    print(f\"...Copy to GDrive complete. Took {time.time() - start_time:.2f}s.\")\n",
        "\n",
        "    # Clean up local VM\n",
        "    print(\"Cleaning up local VM workspace...\")\n",
        "    !rm \"{LOCAL_TAR_FILE}\"\n",
        "    !rm -r \"{local_path_to_copy}\"\n",
        "    print(\"...VM workspace clean.\")\n",
        "\n",
        "print(\"\\n--- PHASE 2 Complete: Setup script finished. ---\")\n",
        "print(f\"Contents of {EXTRACTED_DIR_ON_DRIVE} (for browsing):\")\n",
        "!ls -lh \"$EXTRACTED_DIR_ON_DRIVE\""
      ],
      "metadata": {
        "id": "HOuncWxy0HvZ"
      },
      "id": "HOuncWxy0HvZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}