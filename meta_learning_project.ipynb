{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcvonrohr/DeepLearning/blob/main/meta_learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "54242527",
      "metadata": {
        "id": "54242527",
        "outputId": "fd03eced-2850-4443-f14c-3636139e8d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting Google Drive...\n",
            "Mounted at /content/drive\n",
            "...Google Drive connected.\n",
            "Local data directory created at: /content/data/inaturalist_unpacked\n",
            "\n",
            "--- Processing 2021_train_mini ---\n",
            "Copying '2021_train_mini.tar.gz' from Drive to local VM...\n",
            "...Copy complete. Took 886.47 seconds.\n",
            "Unpacking '2021_train_mini.tar.gz' locally...\n",
            "...Unpacking complete. Took 715.08 seconds.\n",
            "Deleting local tarball '/content/data/2021_train_mini.tar.gz'...\n",
            "...Local tarball deleted.\n",
            "\n",
            "--- Processing 2021_valid ---\n",
            "Copying '2021_valid.tar.gz' from Drive to local VM...\n",
            "...Copy complete. Took 158.36 seconds.\n",
            "Unpacking '2021_valid.tar.gz' locally...\n",
            "...Unpacking complete. Took 143.66 seconds.\n",
            "Deleting local tarball '/content/data/2021_valid.tar.gz'...\n",
            "...Local tarball deleted.\n",
            "\n",
            "--- Final Data Setup Verification ---\n",
            "Dataset is ready for training at: /content/data/inaturalist_unpacked\n",
            "total 2.5M\n",
            "drwxrwxr-x 10002 1000 1000 1.3M Oct 13  2020 train_mini\n",
            "drwxrwxr-x 10002 1000 1000 1.3M Oct 13  2020 val\n",
            "\n",
            "Local VM Disk Space Usage:\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         226G   98G  128G  44% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  750M  62% /usr/sbin/docker-init\n",
            "/dev/sda1       233G  142G   91G  62% /kaggle/input\n",
            "tmpfs           6.4G  108K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "drive           226G  105G  122G  47% /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "#################################################################\n",
        "#  STEP 2.1: PREPARE LOCAL VM\n",
        "#################################################################\n",
        "\n",
        "# --- 1. Mount Google Drive ---\n",
        "print(\"Connecting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"...Google Drive connected.\")\n",
        "\n",
        "# --- 2. Define Key Paths ---\n",
        "GDRIVE_ROOT = '/content/drive/MyDrive/'\n",
        "PROJECT_DIR = os.path.join(GDRIVE_ROOT, 'Deep Learning')\n",
        "DATASETS_ROOT_DIR = os.path.join(PROJECT_DIR, 'datasets')\n",
        "INAT_ROOT_DIR = os.path.join(DATASETS_ROOT_DIR, 'inaturalist')\n",
        "\n",
        "# Source: The COMPRESSED archives\n",
        "ARCHIVES_DIR_ON_DRIVE = os.path.join(INAT_ROOT_DIR, 'archives')\n",
        "\n",
        "# Target: The LOCAL VM fast disk\n",
        "LOCAL_DATA_ROOT = '/content/data'\n",
        "# This is the final path your PyTorch code will use:\n",
        "FINAL_DATA_PATH = os.path.join(LOCAL_DATA_ROOT, 'inaturalist_unpacked')\n",
        "\n",
        "# Define source/destination paths\n",
        "TAR_FILES = {\n",
        "    \"2021_train_mini\": {\n",
        "        \"src\": os.path.join(ARCHIVES_DIR_ON_DRIVE, '2021_train_mini.tar.gz'),\n",
        "        \"dest_tar\": os.path.join(LOCAL_DATA_ROOT, '2021_train_mini.tar.gz'),\n",
        "        \"check_unpacked\": os.path.join(FINAL_DATA_PATH, '2021_train_mini')\n",
        "    },\n",
        "    \"2021_valid\": {\n",
        "        \"src\": os.path.join(ARCHIVES_DIR_ON_DRIVE, '2021_valid.tar.gz'),\n",
        "        \"dest_tar\": os.path.join(LOCAL_DATA_ROOT, '2021_valid.tar.gz'),\n",
        "        \"check_unpacked\": os.path.join(FINAL_DATA_PATH, '2021_valid')\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- 3. Create Local Directories on VM ---\n",
        "os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
        "os.makedirs(FINAL_DATA_PATH, exist_ok=True)\n",
        "print(f\"Local data directory created at: {FINAL_DATA_PATH}\")\n",
        "\n",
        "# --- 4. Copy, Unpack, and Clean up for each file ---\n",
        "for name, paths in TAR_FILES.items():\n",
        "    print(f\"\\n--- Processing {name} ---\")\n",
        "\n",
        "    if os.path.exists(paths[\"check_unpacked\"]):\n",
        "        print(f\"'{name}' is already unpacked in local VM. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # 4a. Copy .tar.gz from Drive to local VM\n",
        "    print(f\"Copying '{name}.tar.gz' from Drive to local VM...\")\n",
        "    start_time = time.time()\n",
        "    !cp \"{paths['src']}\" \"{paths['dest_tar']}\"\n",
        "    print(f\"...Copy complete. Took {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    # 4b. Unpack the file on the local VM\n",
        "    print(f\"Unpacking '{name}.tar.gz' locally...\")\n",
        "    start_time = time.time()\n",
        "    !tar -xzf \"{paths['dest_tar']}\" -C \"{FINAL_DATA_PATH}\"\n",
        "    print(f\"...Unpacking complete. Took {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    # 4c. Delete the local .tar.gz file to save VM space\n",
        "    print(f\"Deleting local tarball '{paths['dest_tar']}'...\")\n",
        "    !rm \"{paths['dest_tar']}\"\n",
        "    print(\"...Local tarball deleted.\")\n",
        "\n",
        "# --- 5. Verify and Set Path for Training ---\n",
        "print(\"\\n--- Final Data Setup Verification ---\")\n",
        "print(f\"Dataset is ready for training at: {FINAL_DATA_PATH}\")\n",
        "!ls -lh \"{FINAL_DATA_PATH}\"\n",
        "print(\"\\nLocal VM Disk Space Usage:\")\n",
        "!df -h"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  STEP 2.2: SCIENTIFIC DATA PARTITIONING\n",
        "#################################################################\n",
        "print(\"\\n--- STEP 2.2: Loading/Creating Scientific Class Partition ---\")\n",
        "\n",
        "# --- 6. Define Paths for Partition File ---\n",
        "# We create a 'project_meta' folder on GDrive to store helper files\n",
        "META_DIR_ON_DRIVE = os.path.join(PROJECT_DIR, 'project_meta')\n",
        "os.makedirs(META_DIR_ON_DRIVE, exist_ok=True)\n",
        "\n",
        "PARTITION_FILE_PATH = os.path.join(META_DIR_ON_DRIVE, 'inat_class_split.json')\n",
        "print(f\"Looking for partition file at: {PARTITION_FILE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_ARRY2GUvXt",
        "outputId": "031acef8-f7b8-421a-ff2b-3451b866167c"
      },
      "id": "1_ARRY2GUvXt",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STEP 2.2: Loading/Creating Scientific Class Partition ---\n",
            "Looking for partition file at: /content/drive/MyDrive/Deep Learning/project_meta/inat_class_split.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Logic to Find Classes and Create Partition ---\n",
        "\n",
        "# 7a. Identify the Dataset Root\n",
        "# The unpacking might have created a subfolder (e.g., '2021_train_mini' or 'train_mini')\n",
        "# or files might be directly in FINAL_DATA_PATH. We check common patterns.\n",
        "possible_roots = [\n",
        "    os.path.join(FINAL_DATA_PATH, '2021_train_mini'),\n",
        "    os.path.join(FINAL_DATA_PATH, 'train_mini'),\n",
        "    FINAL_DATA_PATH\n",
        "]\n",
        "\n",
        "DATASET_ROOT = None\n",
        "for path in possible_roots:\n",
        "    if os.path.exists(path):\n",
        "        # Check if this path actually contains subdirectories\n",
        "        if len([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]) > 0:\n",
        "            DATASET_ROOT = path\n",
        "            break\n",
        "\n",
        "print(f\"Dataset root identified as: {DATASET_ROOT}\")\n",
        "\n",
        "# 7b. Load or Create the Partition\n",
        "partition_data = {}\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "if os.path.exists(PARTITION_FILE_PATH):\n",
        "    print(\"Found existing partition file. Loading...\")\n",
        "    with open(PARTITION_FILE_PATH, 'r') as f:\n",
        "        partition_data = json.load(f)\n",
        "else:\n",
        "    print(\"No partition file found. Scanning directories to create new partition...\")\n",
        "    print(\"This ensures independence from missing metadata files.\")\n",
        "\n",
        "    # --- Scan for Class Folders ---\n",
        "    class_folders_rel = []\n",
        "\n",
        "    # Walk through the directory tree\n",
        "    # A \"class\" is any folder that contains image files (.jpg, .jpeg, .png)\n",
        "    print(\"Scanning folders (this may take 1-2 minutes)...\")\n",
        "    for root, dirs, files in os.walk(DATASET_ROOT):\n",
        "        # Check for images in this specific folder\n",
        "        images = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "        if len(images) > 0:\n",
        "            # Get path relative to the dataset root (e.g., \"Aves/Turdus_migratorius\")\n",
        "            rel_path = os.path.relpath(root, DATASET_ROOT)\n",
        "            class_folders_rel.append(rel_path)\n",
        "\n",
        "    # --- CRITICAL: Sort for Reproducibility ---\n",
        "    # Sorting ensures that Index 0 is ALWAYS the same class on every machine/run\n",
        "    class_folders_rel.sort()\n",
        "\n",
        "    num_classes = len(class_folders_rel)\n",
        "    print(f\"Found {num_classes} classes containing images.\")\n",
        "\n",
        "    if num_classes < 9900:\n",
        "        print(\"WARNING: Found significantly fewer than 10,000 classes. Check extraction.\")\n",
        "\n",
        "    # --- Assign IDs and Shuffle ---\n",
        "    all_class_ids = list(range(num_classes))\n",
        "\n",
        "    print(f\"Shuffling {num_classes} class IDs with random seed {RANDOM_SEED}...\")\n",
        "    random.seed(RANDOM_SEED)\n",
        "    random.shuffle(all_class_ids)\n",
        "\n",
        "    # --- Split into Sets ---\n",
        "    # 6000 Base (Train/Meta-Train), 2000 Val (Hyperparams), 2000 Novel (Test)\n",
        "    c_base_ids = all_class_ids[:6000]\n",
        "    c_val_ids = all_class_ids[6000:8000]\n",
        "    c_novel_ids = all_class_ids[8000:]\n",
        "\n",
        "    # --- Construct Data Structure ---\n",
        "    # We save both the sets AND the mapping from ID -> Folder Path\n",
        "    partition_data = {\n",
        "        \"sets\": {\n",
        "            'c_base': sorted(c_base_ids),\n",
        "            'c_val': sorted(c_val_ids),\n",
        "            'c_novel': sorted(c_novel_ids)\n",
        "        },\n",
        "        \"id_to_path\": {\n",
        "            str(i): folder_path for i, folder_path in enumerate(class_folders_rel)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # --- Save to Drive ---\n",
        "    print(f\"Saving new partition and mapping to: {PARTITION_FILE_PATH}\")\n",
        "    with open(PARTITION_FILE_PATH, 'w') as f:\n",
        "        json.dump(partition_data, f, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "987lbsNFU4Qf",
        "outputId": "19cbe6dc-026e-469c-dd76-07679c440ed2"
      },
      "id": "987lbsNFU4Qf",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset root identified as: /content/data/inaturalist_unpacked/train_mini\n",
            "No partition file found. Scanning directories to create new partition...\n",
            "This ensures independence from missing metadata files.\n",
            "Scanning folders (this may take 1-2 minutes)...\n",
            "Found 10000 classes containing images.\n",
            "Shuffling 10000 class IDs with random seed 42...\n",
            "Saving new partition and mapping to: /content/drive/MyDrive/Deep Learning/project_meta/inat_class_split.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Verification ---\n",
        "print(\"\\n--- Partitioning Complete ---\")\n",
        "sets = partition_data['sets']\n",
        "print(f\"Total C_base classes:  {len(sets['c_base'])}\")\n",
        "print(f\"Total C_val classes:   {len(sets['c_val'])}\")\n",
        "print(f\"Total C_novel classes: {len(sets['c_novel'])}\")\n",
        "\n",
        "# Check for overlaps (should be 0)\n",
        "base_set = set(sets['c_base'])\n",
        "val_set = set(sets['c_val'])\n",
        "novel_set = set(sets['c_novel'])\n",
        "\n",
        "overlap_bv = base_set & val_set\n",
        "overlap_bn = base_set & novel_set\n",
        "overlap_vn = val_set & novel_set\n",
        "\n",
        "print(f\"Overlap (Base-Val):    {len(overlap_bv)}\")\n",
        "print(f\"Overlap (Base-Novel):  {len(overlap_bn)}\")\n",
        "print(f\"Overlap (Val-Novel):   {len(overlap_vn)}\")\n",
        "\n",
        "if len(overlap_bv) + len(overlap_bn) + len(overlap_vn) == 0:\n",
        "    print(\"\\nSUCCESS: Classes are cleanly partitioned.\")\n",
        "else:\n",
        "    print(\"\\nCRITICAL ERROR: Overlaps detected in class sets!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8xIL6YPU6OM",
        "outputId": "2555aeeb-c15b-4b07-9182-8179f8698ebd"
      },
      "id": "w8xIL6YPU6OM",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Partitioning Complete ---\n",
            "Total C_base classes:  6000\n",
            "Total C_val classes:   2000\n",
            "Total C_novel classes: 2000\n",
            "Overlap (Base-Val):    0\n",
            "Overlap (Base-Novel):  0\n",
            "Overlap (Val-Novel):   0\n",
            "\n",
            "SUCCESS: Classes are cleanly partitioned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  STEP 2.3: MODULAR DATA LOADERS (NO LEARN2LEARN DEPENDENCY)\n",
        "#################################################################\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "\n",
        "print(\"\\n--- STEP 2.3: Initialize Custom Data Loaders (Native PyTorch) ---\")\n",
        "\n",
        "# --- SAFETY CHECK ---\n",
        "# Ensure variables from Step 2.2 exist\n",
        "required_vars = ['DATASET_ROOT', 'PARTITION_FILE_PATH']\n",
        "if not all(v in globals() for v in required_vars):\n",
        "    raise NameError(f\"Missing variables from Step 2.2. Please run the previous cell.\")\n",
        "\n",
        "print(f\"Using Dataset Root: {DATASET_ROOT}\")\n",
        "print(f\"Using Partition File: {PARTITION_FILE_PATH}\")\n",
        "\n",
        "# --- CONSTANTS ---\n",
        "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
        "NORMALIZE_STD = [0.229, 0.224, 0.225]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ7TNDctB_kt",
        "outputId": "715b1d41-f119-483d-87b2-f268728e165b"
      },
      "id": "ZZ7TNDctB_kt",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STEP 2.3: Initialize Custom Data Loaders (Native PyTorch) ---\n",
            "Using Dataset Root: /content/data/inaturalist_unpacked/train_mini\n",
            "Using Partition File: /content/drive/MyDrive/Deep Learning/project_meta/inat_class_split.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  CORE COMPONENT: The Custom Dataset Class\n",
        "# ==============================================================================\n",
        "class MetaINatDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom PyTorch Dataset that enforces the scientific partition.\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, partition_file, split='c_base', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "\n",
        "        with open(partition_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if split not in data['sets']:\n",
        "            raise ValueError(f\"Invalid split '{split}'. Available: {list(data['sets'].keys())}\")\n",
        "\n",
        "        self.allowed_ids = data['sets'][split]\n",
        "        self.id_to_path = data['id_to_path']\n",
        "\n",
        "        # Map original ID -> 0..N-1\n",
        "        self.label_map = {orig: new for new, orig in enumerate(self.allowed_ids)}\n",
        "\n",
        "        self.samples = []\n",
        "        for original_id in self.allowed_ids:\n",
        "            rel_path = self.id_to_path[str(original_id)]\n",
        "            abs_path = os.path.join(self.root_dir, rel_path)\n",
        "            if os.path.exists(abs_path):\n",
        "                for img in os.listdir(abs_path):\n",
        "                    if img.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                        self.samples.append({\n",
        "                            'path': os.path.join(abs_path, img),\n",
        "                            'label': self.label_map[original_id]\n",
        "                        })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        image = Image.open(sample['path']).convert('RGB')\n",
        "        label = sample['label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ykdP8nDFcU6i"
      },
      "id": "ykdP8nDFcU6i",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  HELPER: Episodic Batch Generator (Replaces learn2learn)\n",
        "# ==============================================================================\n",
        "class EpisodicTaskGenerator:\n",
        "    \"\"\"\n",
        "    Native PyTorch implementation of an N-Way K-Shot task sampler.\n",
        "    Replaces learn2learn functionality without installation issues.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, ways, shots, query_shots):\n",
        "        self.dataset = dataset\n",
        "        self.ways = ways\n",
        "        self.shots = shots\n",
        "        self.query_shots = query_shots\n",
        "\n",
        "        # Group all image indices by their label for fast sampling\n",
        "        self.indices_by_label = {}\n",
        "        for idx, sample in enumerate(dataset.samples):\n",
        "            lbl = sample['label']\n",
        "            if lbl not in self.indices_by_label:\n",
        "                self.indices_by_label[lbl] = []\n",
        "            self.indices_by_label[lbl].append(idx)\n",
        "\n",
        "        self.classes = list(self.indices_by_label.keys())\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # 1. Sample N random classes (Ways)\n",
        "        selected_classes = random.sample(self.classes, self.ways)\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        # 2. Sample K + Q images from each class\n",
        "        for local_label, global_label_idx in enumerate(selected_classes):\n",
        "            indices = self.indices_by_label[global_label_idx]\n",
        "\n",
        "            # Ensure we have enough images, otherwise sample with replacement\n",
        "            needed = self.shots + self.query_shots\n",
        "            if len(indices) >= needed:\n",
        "                selected_indices = random.sample(indices, needed)\n",
        "            else:\n",
        "                selected_indices = random.choices(indices, k=needed)\n",
        "\n",
        "            # 3. Load images and re-label them to 0..N-1 for the episode\n",
        "            for idx in selected_indices:\n",
        "                img, _ = self.dataset[idx] # dataset returns (img, global_label)\n",
        "                batch_images.append(img)\n",
        "                # Important: The label for the loss function must be 0..Ways-1\n",
        "                batch_labels.append(local_label)\n",
        "\n",
        "        # Stack into a single tensor: [Ways * (Shots+Query), C, H, W]\n",
        "        data = torch.stack(batch_images)\n",
        "        labels = torch.tensor(batch_labels)\n",
        "\n",
        "        return data, labels\n",
        "\n",
        "    def sample(self):\n",
        "        # Compatibility method to look like learn2learn\n",
        "        return self.__next__()"
      ],
      "metadata": {
        "id": "asZAUP18cfqQ"
      },
      "id": "asZAUP18cfqQ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  LOADER A: Standard Pre-Training Loader\n",
        "# ==============================================================================\n",
        "def get_standard_loader(split='c_base', batch_size=64, shuffle=True):\n",
        "    print(f\"\\n[Loader A] Initializing Standard Loader for split '{split}'...\")\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    dataset = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=train_transforms)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(f\" -> {len(dataset)} total images.\")\n",
        "    print(f\" -> {len(dataset.allowed_ids)} classes.\")\n",
        "    return loader, len(dataset.allowed_ids)"
      ],
      "metadata": {
        "id": "oVtAtf9zcm9e"
      },
      "id": "oVtAtf9zcm9e",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  LOADER B: Episodic Task Loader (MAML) - NATIVE IMPLEMENTATION\n",
        "# ==============================================================================\n",
        "def get_episodic_taskset(split='c_base', ways=5, shots=1, query_shots=1, img_size=84):\n",
        "    print(f\"\\n[Loader B] Initializing Episodic Generator for split '{split}'...\")\n",
        "\n",
        "    maml_transforms = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    dataset = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=maml_transforms)\n",
        "\n",
        "    # Use our native generator instead of learn2learn\n",
        "    task_generator = EpisodicTaskGenerator(\n",
        "        dataset,\n",
        "        ways=ways,\n",
        "        shots=shots,\n",
        "        query_shots=query_shots\n",
        "    )\n",
        "\n",
        "    print(f\" -> Configured {ways}-Way {shots}-Shot Tasks (Native PyTorch).\")\n",
        "    return task_generator"
      ],
      "metadata": {
        "id": "madMlUDOc5CK"
      },
      "id": "madMlUDOc5CK",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  LOADER C: Fixed Few-Shot Loader for FT/LoRA\n",
        "# ==============================================================================\n",
        "def get_fixed_few_shot_task(split='c_novel', ways=5, shots=1, query_shots=15, seed=None):\n",
        "    print(f\"\\n[Loader C] Creating Fixed Few-Shot Task from '{split}'...\")\n",
        "\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    eval_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    dataset = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=eval_transforms)\n",
        "\n",
        "    available_labels = list(set(s['label'] for s in dataset.samples))\n",
        "    selected_classes = random.sample(available_labels, ways)\n",
        "\n",
        "    class_indices = {c: [] for c in selected_classes}\n",
        "    for idx, sample in enumerate(dataset.samples):\n",
        "        if sample['label'] in selected_classes:\n",
        "            class_indices[sample['label']].append(idx)\n",
        "\n",
        "    support_indices = []\n",
        "    query_indices = []\n",
        "\n",
        "    for c in selected_classes:\n",
        "        idxs = class_indices[c]\n",
        "        random.shuffle(idxs)\n",
        "        support_indices.extend(idxs[:shots])\n",
        "        query_indices.extend(idxs[shots : shots+query_shots])\n",
        "\n",
        "    support_loader = DataLoader(Subset(dataset, support_indices), batch_size=16, shuffle=True)\n",
        "    query_loader = DataLoader(Subset(dataset, query_indices), batch_size=32, shuffle=False)\n",
        "\n",
        "    print(f\" -> Support Set: {len(support_indices)} images, Query Set: {len(query_indices)} images\")\n",
        "    return support_loader, query_loader"
      ],
      "metadata": {
        "id": "G1m0luxjc5gB"
      },
      "id": "G1m0luxjc5gB",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  VERIFICATION\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Testing Loaders ---\")\n",
        "\n",
        "# Test A\n",
        "try:\n",
        "    l_std, n_cls = get_standard_loader(split='c_base', batch_size=4)\n",
        "    print(\"Loader A (Standard) check: OK.\")\n",
        "except Exception as e:\n",
        "    print(f\"Loader A Failed: {e}\")\n",
        "\n",
        "# Test B (Now using Native Generator)\n",
        "try:\n",
        "    task_gen = get_episodic_taskset(split='c_base', ways=5, shots=1, query_shots=1)\n",
        "    batch_data, batch_labels = task_gen.sample()\n",
        "    # Expected shape: [Way*(Shot+Query), 3, 84, 84] -> [5*(1+1), 3, 84, 84] = [10, 3, 84, 84]\n",
        "    print(f\"Loader B (Episodic) check: OK. Batch shape: {batch_data.shape}\")\n",
        "    if batch_labels.max() >= 5:\n",
        "        print(\"WARNING: Labels not properly remapped to 0..N-1\")\n",
        "except Exception as e:\n",
        "    print(f\"Loader B Failed: {e}\")\n",
        "\n",
        "# Test C\n",
        "try:\n",
        "    sup_dl, q_dl = get_fixed_few_shot_task(split='c_novel', ways=5, shots=5)\n",
        "    print(\"Loader C (Fixed) check: OK.\")\n",
        "except Exception as e:\n",
        "    print(f\"Loader C Failed: {e}\")\n",
        "\n",
        "print(\"\\nStep 2.3 Complete (Dependencies Fixed).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zceGZ_SdEeE",
        "outputId": "5fa17893-5dc6-45d0-90c2-4d22422611b4"
      },
      "id": "3zceGZ_SdEeE",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Loaders ---\n",
            "\n",
            "[Loader A] Initializing Standard Loader for split 'c_base'...\n",
            " -> 300000 total images.\n",
            " -> 6000 classes.\n",
            "Loader A (Standard) check: OK.\n",
            "\n",
            "[Loader B] Initializing Episodic Generator for split 'c_base'...\n",
            " -> Configured 5-Way 1-Shot Tasks (Native PyTorch).\n",
            "Loader B (Episodic) check: OK. Batch shape: torch.Size([10, 3, 84, 84])\n",
            "\n",
            "[Loader C] Creating Fixed Few-Shot Task from 'c_novel'...\n",
            " -> Support Set: 25 images, Query Set: 75 images\n",
            "Loader C (Fixed) check: OK.\n",
            "\n",
            "Step 2.3 Complete (Dependencies Fixed).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  PHASE 4: PRE-TRAINING WITH ROBUST RESUME CAPABILITY\n",
        "#################################################################\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil\n",
        "\n",
        "print(\"\\n--- PHASE 4: Pipeline 0 - Robust Pre-Training ---\")\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "CONFIG = {\n",
        "    'ARCH': 'resnet34',\n",
        "    'DRY_RUN': True,           # Set to False for real training\n",
        "    'BATCH_SIZE': 64,\n",
        "    'LEARNING_RATE': 1e-3,\n",
        "    'NUM_EPOCHS': 20,           # 20 Epochs is a good sweet spot\n",
        "    'PATIENCE': 5,              # Early Stopping Patience\n",
        "    'SUBSETS': [0.25, 0.50, 1.0],\n",
        "\n",
        "    'CHECKPOINT_DIR_LOC': '/content/checkpoints',\n",
        "    'CHECKPOINT_DIR_DRIVE': os.path.join(PROJECT_DIR, 'models', 'base_models')\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG['CHECKPOINT_DIR_LOC'], exist_ok=True)\n",
        "os.makedirs(CONFIG['CHECKPOINT_DIR_DRIVE'], exist_ok=True)\n",
        "\n",
        "# --- 2. MODEL FACTORY (Same as before) ---\n",
        "def get_base_model(arch_name, num_classes, pretrained=True):\n",
        "    if arch_name == 'resnet18':\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n",
        "        in_features = model.fc.in_features\n",
        "    elif arch_name == 'resnet34':\n",
        "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT if pretrained else None)\n",
        "        in_features = model.fc.in_features\n",
        "    elif arch_name == 'resnet50':\n",
        "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT if pretrained else None)\n",
        "        in_features = model.fc.in_features\n",
        "    else:\n",
        "        raise ValueError(\"Arch not supported\")\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# --- 3. DATA LOADER (Same as before) ---\n",
        "# (Assuming MetaINatDataset is defined in Step 2.3 cell)\n",
        "def get_subset_loader(fraction, batch_size):\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "    full_ds = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split='c_base', transform=train_transforms)\n",
        "\n",
        "    target_num = int(len(full_ds.allowed_ids) * fraction)\n",
        "    subset_ids = full_ds.allowed_ids[:target_num]\n",
        "\n",
        "    # Filter samples\n",
        "    new_samples = [s for s in full_ds.samples if s['label'] < target_num]\n",
        "    full_ds.samples = new_samples\n",
        "    full_ds.allowed_ids = subset_ids\n",
        "    full_ds.label_map = {orig: new for new, orig in enumerate(subset_ids)}\n",
        "\n",
        "    print(f\"   [Subset {fraction*100}%] {len(new_samples)} images, {target_num} classes.\")\n",
        "\n",
        "    num_val = int(0.1 * len(full_ds))\n",
        "    train_ds, val_ds = random_split(full_ds, [len(full_ds)-num_val, num_val], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    return (DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True),\n",
        "            DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True),\n",
        "            target_num)\n",
        "\n",
        "# --- 4. CHECKPOINTING HELPER ---\n",
        "def save_full_checkpoint(state, filename):\n",
        "    \"\"\"Saves full state (Model + Optimizer) for resuming.\"\"\"\n",
        "    loc_path = os.path.join(CONFIG['CHECKPOINT_DIR_LOC'], filename)\n",
        "    drv_path = os.path.join(CONFIG['CHECKPOINT_DIR_DRIVE'], filename)\n",
        "    torch.save(state, loc_path)\n",
        "    try:\n",
        "        shutil.copy(loc_path, drv_path)\n",
        "    except Exception as e:\n",
        "        print(f\"   [Warning] Copy to Drive failed: {e}\")\n",
        "\n",
        "def save_weights_only(model, filename):\n",
        "    \"\"\"Saves only weights (Small) for later Phases.\"\"\"\n",
        "    loc_path = os.path.join(CONFIG['CHECKPOINT_DIR_LOC'], filename)\n",
        "    drv_path = os.path.join(CONFIG['CHECKPOINT_DIR_DRIVE'], filename)\n",
        "    torch.save(model.state_dict(), loc_path)\n",
        "    try:\n",
        "        shutil.copy(loc_path, drv_path)\n",
        "    except: pass\n",
        "\n",
        "# --- 5. TRAINING ENGINE (WITH RESUME) ---\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, model_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define filenames\n",
        "    run_tag = \"_dryrun\" if CONFIG['DRY_RUN'] else \"\"\n",
        "    ckpt_name = f\"{model_name}{run_tag}_checkpoint.pth\" # Contains optimizer (Resume)\n",
        "    best_name = f\"{model_name}{run_tag}_best.pth\"       # Contains only weights (Final)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # --- RESUME LOGIC ---\n",
        "    drive_ckpt_path = os.path.join(CONFIG['CHECKPOINT_DIR_DRIVE'], ckpt_name)\n",
        "    if os.path.exists(drive_ckpt_path):\n",
        "        print(f\"\\n[RESUME] Found existing checkpoint at {drive_ckpt_path}\")\n",
        "        print(\"   Loading state to resume training...\")\n",
        "        checkpoint = torch.load(drive_ckpt_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        print(f\"   Resuming from Epoch {start_epoch} with Best Acc: {best_acc:.4f}\")\n",
        "    else:\n",
        "        print(f\"\\n[START] No checkpoint found. Starting fresh training.\")\n",
        "\n",
        "    # Early Stopping Vars\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Main Loop\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # --- TRAIN ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # TQDM for batch progress\n",
        "        pbar = tqdm(train_loader, leave=False, desc=\"Training\")\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(pbar):\n",
        "            if CONFIG['DRY_RUN'] and i >= 5: break\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Stats\n",
        "        iter_size = len(train_loader.dataset) if not CONFIG['DRY_RUN'] else (5 * CONFIG['BATCH_SIZE'])\n",
        "        epoch_loss = running_loss / iter_size\n",
        "        epoch_acc = running_corrects.double() / iter_size\n",
        "\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "        # --- VALIDATION ---\n",
        "        model.eval()\n",
        "        val_corrects = 0\n",
        "\n",
        "        if not CONFIG['DRY_RUN']:\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "            val_acc = val_corrects.double() / len(val_loader.dataset)\n",
        "        else:\n",
        "            val_acc = 0.0\n",
        "\n",
        "        print(f\"   Train Acc: {epoch_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # --- SAVE CHECKPOINT (EVERY EPOCH) ---\n",
        "        # Allows resuming if Colab crashes\n",
        "        full_state = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_acc': best_acc\n",
        "        }\n",
        "        save_full_checkpoint(full_state, ckpt_name)\n",
        "\n",
        "        # --- SAVE BEST MODEL ---\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            save_weights_only(model, best_name) # Save lightweight version for Phase 5\n",
        "            print(f\"   [New Best] Saved {best_name}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # --- EARLY STOPPING ---\n",
        "        if not CONFIG['DRY_RUN'] and patience_counter >= CONFIG['PATIENCE']:\n",
        "            print(f\"   [Early Stopping] No improvement for {CONFIG['PATIENCE']} epochs.\")\n",
        "            break\n",
        "\n",
        "        if CONFIG['DRY_RUN']:\n",
        "            print(\"   [Dry Run] Stopping after 1 epoch.\")\n",
        "            break\n",
        "\n",
        "    print(f\"Training Finished. Best Validation Accuracy: {best_acc:.4f}\")\n",
        "    return model\n",
        "\n",
        "# --- 6. MAIN EXECUTION ---\n",
        "for fraction in CONFIG['SUBSETS']:\n",
        "    subset_name = f\"M_base_{int(fraction*100)}\"\n",
        "    print(f\"\\n{'='*40}\\nPRE-TRAINING: {subset_name}\\n{'='*40}\")\n",
        "\n",
        "    train_dl, val_dl, num_cls = get_subset_loader(fraction, CONFIG['BATCH_SIZE'])\n",
        "    model = get_base_model(CONFIG['ARCH'], num_classes=num_cls)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['LEARNING_RATE'])\n",
        "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "    train_model(model, train_dl, val_dl, criterion, optimizer, lr_scheduler, CONFIG['NUM_EPOCHS'], subset_name)"
      ],
      "metadata": {
        "id": "BbiMjGzgloUw"
      },
      "id": "BbiMjGzgloUw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}