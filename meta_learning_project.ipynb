{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcvonrohr/DeepLearning/blob/main/meta_learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54242527",
      "metadata": {
        "id": "54242527",
        "outputId": "bb1ec5bc-b721-4f7a-b5b7-7a6112d010d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "...Google Drive connected.\n",
            "Local data directory created at: /content/data/inaturalist_unpacked\n",
            "\n",
            "--- Processing 2021_train_mini ---\n",
            "Copying '2021_train_mini.tar.gz' from Drive to local VM...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "#################################################################\n",
        "#  STEP 2.1: PREPARE LOCAL VM\n",
        "#################################################################\n",
        "\n",
        "# --- 1. Mount Google Drive ---\n",
        "print(\"Connecting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"...Google Drive connected.\")\n",
        "\n",
        "# --- 2. Define Key Paths ---\n",
        "GDRIVE_ROOT = '/content/drive/MyDrive/'\n",
        "PROJECT_DIR = os.path.join(GDRIVE_ROOT, 'Deep Learning')\n",
        "DATASETS_ROOT_DIR = os.path.join(PROJECT_DIR, 'datasets')\n",
        "INAT_ROOT_DIR = os.path.join(DATASETS_ROOT_DIR, 'inaturalist')\n",
        "\n",
        "# Source: The COMPRESSED archives\n",
        "ARCHIVES_DIR_ON_DRIVE = os.path.join(INAT_ROOT_DIR, 'archives')\n",
        "\n",
        "# Target: The LOCAL VM fast disk\n",
        "LOCAL_DATA_ROOT = '/content/data'\n",
        "# This is the final path your PyTorch code will use:\n",
        "FINAL_DATA_PATH = os.path.join(LOCAL_DATA_ROOT, 'inaturalist_unpacked')\n",
        "\n",
        "# Define source/destination paths\n",
        "TAR_FILES = {\n",
        "    \"2021_train_mini\": {\n",
        "        \"src\": os.path.join(ARCHIVES_DIR_ON_DRIVE, '2021_train_mini.tar.gz'),\n",
        "        \"dest_tar\": os.path.join(LOCAL_DATA_ROOT, '2021_train_mini.tar.gz'),\n",
        "        \"check_unpacked\": os.path.join(FINAL_DATA_PATH, '2021_train_mini')\n",
        "    },\n",
        "    \"2021_valid\": {\n",
        "        \"src\": os.path.join(ARCHIVES_DIR_ON_DRIVE, '2021_valid.tar.gz'),\n",
        "        \"dest_tar\": os.path.join(LOCAL_DATA_ROOT, '2021_valid.tar.gz'),\n",
        "        \"check_unpacked\": os.path.join(FINAL_DATA_PATH, '2021_valid')\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- 3. Create Local Directories on VM ---\n",
        "os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
        "os.makedirs(FINAL_DATA_PATH, exist_ok=True)\n",
        "print(f\"Local data directory created at: {FINAL_DATA_PATH}\")\n",
        "\n",
        "# --- 4. Copy, Unpack, and Clean up for each file ---\n",
        "for name, paths in TAR_FILES.items():\n",
        "    print(f\"\\n--- Processing {name} ---\")\n",
        "\n",
        "    if os.path.exists(paths[\"check_unpacked\"]):\n",
        "        print(f\"'{name}' is already unpacked in local VM. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # 4a. Copy .tar.gz from Drive to local VM\n",
        "    print(f\"Copying '{name}.tar.gz' from Drive to local VM...\")\n",
        "    start_time = time.time()\n",
        "    !cp \"{paths['src']}\" \"{paths['dest_tar']}\"\n",
        "    print(f\"...Copy complete. Took {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    # 4b. Unpack the file on the local VM\n",
        "    print(f\"Unpacking '{name}.tar.gz' locally...\")\n",
        "    start_time = time.time()\n",
        "    !tar -xzf \"{paths['dest_tar']}\" -C \"{FINAL_DATA_PATH}\"\n",
        "    print(f\"...Unpacking complete. Took {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    # 4c. Delete the local .tar.gz file to save VM space\n",
        "    print(f\"Deleting local tarball '{paths['dest_tar']}'...\")\n",
        "    !rm \"{paths['dest_tar']}\"\n",
        "    print(\"...Local tarball deleted.\")\n",
        "\n",
        "# --- 5. Verify and Set Path for Training ---\n",
        "print(\"\\n--- Final Data Setup Verification ---\")\n",
        "print(f\"Dataset is ready for training at: {FINAL_DATA_PATH}\")\n",
        "!ls -lh \"{FINAL_DATA_PATH}\"\n",
        "print(\"\\nLocal VM Disk Space Usage:\")\n",
        "!df -h"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  STEP 2.2: SCIENTIFIC DATA PARTITIONING\n",
        "#################################################################\n",
        "print(\"\\n--- STEP 2.2: Loading/Creating Scientific Class Partition ---\")\n",
        "\n",
        "# --- 6. Define Paths for Partition File ---\n",
        "# We create a 'project_meta' folder on GDrive to store helper files\n",
        "META_DIR_ON_DRIVE = os.path.join(PROJECT_DIR, 'project_meta')\n",
        "os.makedirs(META_DIR_ON_DRIVE, exist_ok=True)\n",
        "\n",
        "PARTITION_FILE_PATH = os.path.join(META_DIR_ON_DRIVE, 'inat_class_split.json')\n",
        "print(f\"Looking for partition file at: {PARTITION_FILE_PATH}\")"
      ],
      "metadata": {
        "id": "1_ARRY2GUvXt"
      },
      "id": "1_ARRY2GUvXt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Logic to Find Classes and Create Partition ---\n",
        "\n",
        "# 7a. Identify the Dataset Root\n",
        "# The unpacking might have created a subfolder (e.g., '2021_train_mini' or 'train_mini')\n",
        "# or files might be directly in FINAL_DATA_PATH. We check common patterns.\n",
        "possible_roots = [\n",
        "    os.path.join(FINAL_DATA_PATH, '2021_train_mini'),\n",
        "    os.path.join(FINAL_DATA_PATH, 'train_mini'),\n",
        "    FINAL_DATA_PATH\n",
        "]\n",
        "\n",
        "DATASET_ROOT = None\n",
        "for path in possible_roots:\n",
        "    if os.path.exists(path):\n",
        "        # Check if this path actually contains subdirectories\n",
        "        if len([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]) > 0:\n",
        "            DATASET_ROOT = path\n",
        "            break\n",
        "\n",
        "print(f\"Dataset root identified as: {DATASET_ROOT}\")\n",
        "\n",
        "# 7b. Load or Create the Partition\n",
        "partition_data = {}\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "if os.path.exists(PARTITION_FILE_PATH):\n",
        "    print(\"Found existing partition file. Loading...\")\n",
        "    with open(PARTITION_FILE_PATH, 'r') as f:\n",
        "        partition_data = json.load(f)\n",
        "else:\n",
        "    print(\"No partition file found. Scanning directories to create new partition...\")\n",
        "    print(\"This ensures independence from missing metadata files.\")\n",
        "\n",
        "    # --- Scan for Class Folders ---\n",
        "    class_folders_rel = []\n",
        "\n",
        "    # Walk through the directory tree\n",
        "    # A \"class\" is any folder that contains image files (.jpg, .jpeg, .png)\n",
        "    print(\"Scanning folders (this may take 1-2 minutes)...\")\n",
        "    for root, dirs, files in os.walk(DATASET_ROOT):\n",
        "        # Check for images in this specific folder\n",
        "        images = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "        if len(images) > 0:\n",
        "            # Get path relative to the dataset root (e.g., \"Aves/Turdus_migratorius\")\n",
        "            rel_path = os.path.relpath(root, DATASET_ROOT)\n",
        "            class_folders_rel.append(rel_path)\n",
        "\n",
        "    # --- CRITICAL: Sort for Reproducibility ---\n",
        "    # Sorting ensures that Index 0 is ALWAYS the same class on every machine/run\n",
        "    class_folders_rel.sort()\n",
        "\n",
        "    num_classes = len(class_folders_rel)\n",
        "    print(f\"Found {num_classes} classes containing images.\")\n",
        "\n",
        "    if num_classes < 9900:\n",
        "        print(\"WARNING: Found significantly fewer than 10,000 classes. Check extraction.\")\n",
        "\n",
        "    # --- Assign IDs and Shuffle ---\n",
        "    all_class_ids = list(range(num_classes))\n",
        "\n",
        "    print(f\"Shuffling {num_classes} class IDs with random seed {RANDOM_SEED}...\")\n",
        "    random.seed(RANDOM_SEED)\n",
        "    random.shuffle(all_class_ids)\n",
        "\n",
        "    # --- Split into Sets ---\n",
        "    # 6000 Base (Train/Meta-Train), 2000 Val (Hyperparams), 2000 Novel (Test)\n",
        "    c_base_ids = all_class_ids[:6000]\n",
        "    c_val_ids = all_class_ids[6000:8000]\n",
        "    c_novel_ids = all_class_ids[8000:]\n",
        "\n",
        "    # --- Construct Data Structure ---\n",
        "    # We save both the sets AND the mapping from ID -> Folder Path\n",
        "    partition_data = {\n",
        "        \"sets\": {\n",
        "            'c_base': sorted(c_base_ids),\n",
        "            'c_val': sorted(c_val_ids),\n",
        "            'c_novel': sorted(c_novel_ids)\n",
        "        },\n",
        "        \"id_to_path\": {\n",
        "            str(i): folder_path for i, folder_path in enumerate(class_folders_rel)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # --- Save to Drive ---\n",
        "    print(f\"Saving new partition and mapping to: {PARTITION_FILE_PATH}\")\n",
        "    with open(PARTITION_FILE_PATH, 'w') as f:\n",
        "        json.dump(partition_data, f, indent=4)"
      ],
      "metadata": {
        "id": "987lbsNFU4Qf"
      },
      "id": "987lbsNFU4Qf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Verification ---\n",
        "print(\"\\n--- Partitioning Complete ---\")\n",
        "sets = partition_data['sets']\n",
        "print(f\"Total C_base classes:  {len(sets['c_base'])}\")\n",
        "print(f\"Total C_val classes:   {len(sets['c_val'])}\")\n",
        "print(f\"Total C_novel classes: {len(sets['c_novel'])}\")\n",
        "\n",
        "# Check for overlaps (should be 0)\n",
        "base_set = set(sets['c_base'])\n",
        "val_set = set(sets['c_val'])\n",
        "novel_set = set(sets['c_novel'])\n",
        "\n",
        "overlap_bv = base_set & val_set\n",
        "overlap_bn = base_set & novel_set\n",
        "overlap_vn = val_set & novel_set\n",
        "\n",
        "print(f\"Overlap (Base-Val):    {len(overlap_bv)}\")\n",
        "print(f\"Overlap (Base-Novel):  {len(overlap_bn)}\")\n",
        "print(f\"Overlap (Val-Novel):   {len(overlap_vn)}\")\n",
        "\n",
        "if len(overlap_bv) + len(overlap_bn) + len(overlap_vn) == 0:\n",
        "    print(\"\\nSUCCESS: Classes are cleanly partitioned.\")\n",
        "else:\n",
        "    print(\"\\nCRITICAL ERROR: Overlaps detected in class sets!\")"
      ],
      "metadata": {
        "id": "w8xIL6YPU6OM"
      },
      "id": "w8xIL6YPU6OM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  STEP 2.3: MODULAR DATA LOADERS (NO LEARN2LEARN DEPENDENCY)\n",
        "#################################################################\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "\n",
        "print(\"\\n--- STEP 2.3: Initialize Custom Data Loaders (Native PyTorch) ---\")\n",
        "\n",
        "# --- SAFETY CHECK ---\n",
        "# Ensure variables from Step 2.2 exist\n",
        "required_vars = ['DATASET_ROOT', 'PARTITION_FILE_PATH']\n",
        "if not all(v in globals() for v in required_vars):\n",
        "    raise NameError(f\"Missing variables from Step 2.2. Please run the previous cell.\")\n",
        "\n",
        "print(f\"Using Dataset Root: {DATASET_ROOT}\")\n",
        "print(f\"Using Partition File: {PARTITION_FILE_PATH}\")\n",
        "\n",
        "# --- CONSTANTS ---\n",
        "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
        "NORMALIZE_STD = [0.229, 0.224, 0.225]"
      ],
      "metadata": {
        "id": "ZZ7TNDctB_kt"
      },
      "id": "ZZ7TNDctB_kt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  CORE COMPONENT: The Custom Dataset Class\n",
        "# ==============================================================================\n",
        "class MetaINatDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom PyTorch Dataset that enforces the scientific partition.\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, partition_file, split='c_base', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "\n",
        "        with open(partition_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if split not in data['sets']:\n",
        "            raise ValueError(f\"Invalid split '{split}'. Available: {list(data['sets'].keys())}\")\n",
        "\n",
        "        self.allowed_ids = data['sets'][split]\n",
        "        self.id_to_path = data['id_to_path']\n",
        "\n",
        "        # Map original ID -> 0..N-1\n",
        "        self.label_map = {orig: new for new, orig in enumerate(self.allowed_ids)}\n",
        "\n",
        "        self.samples = []\n",
        "        for original_id in self.allowed_ids:\n",
        "            rel_path = self.id_to_path[str(original_id)]\n",
        "            abs_path = os.path.join(self.root_dir, rel_path)\n",
        "            if os.path.exists(abs_path):\n",
        "                for img in os.listdir(abs_path):\n",
        "                    if img.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                        self.samples.append({\n",
        "                            'path': os.path.join(abs_path, img),\n",
        "                            'label': self.label_map[original_id]\n",
        "                        })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        image = Image.open(sample['path']).convert('RGB')\n",
        "        label = sample['label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ykdP8nDFcU6i"
      },
      "id": "ykdP8nDFcU6i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  HELPER: Episodic Batch Generator (Replaces learn2learn)\n",
        "# ==============================================================================\n",
        "class EpisodicTaskGenerator:\n",
        "    \"\"\"\n",
        "    Native PyTorch implementation of an N-Way K-Shot task sampler.\n",
        "    Replaces learn2learn functionality without installation issues.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, ways, shots, query_shots):\n",
        "        self.dataset = dataset\n",
        "        self.ways = ways\n",
        "        self.shots = shots\n",
        "        self.query_shots = query_shots\n",
        "\n",
        "        # Group all image indices by their label for fast sampling\n",
        "        self.indices_by_label = {}\n",
        "        for idx, sample in enumerate(dataset.samples):\n",
        "            lbl = sample['label']\n",
        "            if lbl not in self.indices_by_label:\n",
        "                self.indices_by_label[lbl] = []\n",
        "            self.indices_by_label[lbl].append(idx)\n",
        "\n",
        "        self.classes = list(self.indices_by_label.keys())\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # 1. Sample N random classes (Ways)\n",
        "        selected_classes = random.sample(self.classes, self.ways)\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        # 2. Sample K + Q images from each class\n",
        "        for local_label, global_label_idx in enumerate(selected_classes):\n",
        "            indices = self.indices_by_label[global_label_idx]\n",
        "\n",
        "            # Ensure we have enough images, otherwise sample with replacement\n",
        "            needed = self.shots + self.query_shots\n",
        "            if len(indices) >= needed:\n",
        "                selected_indices = random.sample(indices, needed)\n",
        "            else:\n",
        "                selected_indices = random.choices(indices, k=needed)\n",
        "\n",
        "            # 3. Load images and re-label them to 0..N-1 for the episode\n",
        "            for idx in selected_indices:\n",
        "                img, _ = self.dataset[idx] # dataset returns (img, global_label)\n",
        "                batch_images.append(img)\n",
        "                # Important: The label for the loss function must be 0..Ways-1\n",
        "                batch_labels.append(local_label)\n",
        "\n",
        "        # Stack into a single tensor: [Ways * (Shots+Query), C, H, W]\n",
        "        data = torch.stack(batch_images)\n",
        "        labels = torch.tensor(batch_labels)\n",
        "\n",
        "        return data, labels\n",
        "\n",
        "    def sample(self):\n",
        "        # Compatibility method to look like learn2learn\n",
        "        return self.__next__()"
      ],
      "metadata": {
        "id": "asZAUP18cfqQ"
      },
      "id": "asZAUP18cfqQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  LOADER A: Standard Pre-Training Loader\n",
        "# ==============================================================================\n",
        "def get_standard_loader(split='c_base', batch_size=64, shuffle=True):\n",
        "    print(f\"\\n[Loader A] Initializing Standard Loader for split '{split}'...\")\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    dataset = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=train_transforms)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(f\" -> {len(dataset)} total images.\")\n",
        "    print(f\" -> {len(dataset.allowed_ids)} classes.\")\n",
        "    return loader, len(dataset.allowed_ids)"
      ],
      "metadata": {
        "id": "oVtAtf9zcm9e"
      },
      "id": "oVtAtf9zcm9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  LOADER B: Episodic Task Loader (MAML) - NATIVE IMPLEMENTATION\n",
        "# ==============================================================================\n",
        "def get_episodic_taskset(split='c_base', ways=5, shots=1, query_shots=1, img_size=84):\n",
        "    print(f\"\\n[Loader B] Initializing Episodic Generator for split '{split}'...\")\n",
        "\n",
        "    maml_transforms = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    dataset = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=maml_transforms)\n",
        "\n",
        "    # Use our native generator instead of learn2learn\n",
        "    task_generator = EpisodicTaskGenerator(\n",
        "        dataset,\n",
        "        ways=ways,\n",
        "        shots=shots,\n",
        "        query_shots=query_shots\n",
        "    )\n",
        "\n",
        "    print(f\" -> Configured {ways}-Way {shots}-Shot Tasks (Native PyTorch).\")\n",
        "    return task_generator"
      ],
      "metadata": {
        "id": "madMlUDOc5CK"
      },
      "id": "madMlUDOc5CK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  LOADER C: Fixed Few-Shot Loader for FT/LoRA\n",
        "# ==============================================================================\n",
        "def get_fixed_few_shot_task(split='c_novel', ways=5, shots=1, query_shots=15, seed=None):\n",
        "    print(f\"\\n[Loader C] Creating Fixed Few-Shot Task from '{split}'...\")\n",
        "\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    eval_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    dataset = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=eval_transforms)\n",
        "\n",
        "    available_labels = list(set(s['label'] for s in dataset.samples))\n",
        "    selected_classes = random.sample(available_labels, ways)\n",
        "\n",
        "    class_indices = {c: [] for c in selected_classes}\n",
        "    for idx, sample in enumerate(dataset.samples):\n",
        "        if sample['label'] in selected_classes:\n",
        "            class_indices[sample['label']].append(idx)\n",
        "\n",
        "    support_indices = []\n",
        "    query_indices = []\n",
        "\n",
        "    for c in selected_classes:\n",
        "        idxs = class_indices[c]\n",
        "        random.shuffle(idxs)\n",
        "        support_indices.extend(idxs[:shots])\n",
        "        query_indices.extend(idxs[shots : shots+query_shots])\n",
        "\n",
        "    support_loader = DataLoader(Subset(dataset, support_indices), batch_size=16, shuffle=True)\n",
        "    query_loader = DataLoader(Subset(dataset, query_indices), batch_size=32, shuffle=False)\n",
        "\n",
        "    print(f\" -> Support Set: {len(support_indices)} images, Query Set: {len(query_indices)} images\")\n",
        "    return support_loader, query_loader"
      ],
      "metadata": {
        "id": "G1m0luxjc5gB"
      },
      "id": "G1m0luxjc5gB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  VERIFICATION\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Testing Loaders ---\")\n",
        "\n",
        "# Test A\n",
        "try:\n",
        "    l_std, n_cls = get_standard_loader(split='c_base', batch_size=4)\n",
        "    print(\"Loader A (Standard) check: OK.\")\n",
        "except Exception as e:\n",
        "    print(f\"Loader A Failed: {e}\")\n",
        "\n",
        "# Test B (Now using Native Generator)\n",
        "try:\n",
        "    task_gen = get_episodic_taskset(split='c_base', ways=5, shots=1, query_shots=1)\n",
        "    batch_data, batch_labels = task_gen.sample()\n",
        "    # Expected shape: [Way*(Shot+Query), 3, 84, 84] -> [5*(1+1), 3, 84, 84] = [10, 3, 84, 84]\n",
        "    print(f\"Loader B (Episodic) check: OK. Batch shape: {batch_data.shape}\")\n",
        "    if batch_labels.max() >= 5:\n",
        "        print(\"WARNING: Labels not properly remapped to 0..N-1\")\n",
        "except Exception as e:\n",
        "    print(f\"Loader B Failed: {e}\")\n",
        "\n",
        "# Test C\n",
        "try:\n",
        "    sup_dl, q_dl = get_fixed_few_shot_task(split='c_novel', ways=5, shots=5)\n",
        "    print(\"Loader C (Fixed) check: OK.\")\n",
        "except Exception as e:\n",
        "    print(f\"Loader C Failed: {e}\")\n",
        "\n",
        "print(\"\\nStep 2.3 Complete (Dependencies Fixed).\")"
      ],
      "metadata": {
        "id": "3zceGZ_SdEeE"
      },
      "id": "3zceGZ_SdEeE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  PHASE 4: INTELLIGENT PRE-TRAINING (MAX PERF & MEMORY SAFE)\n",
        "#################################################################\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import random\n",
        "import gc  # <--- WICHTIG für Garbage Collection\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"\\n--- PHASE 4: Pipeline 0 - Base Model Pre-Training ---\")\n",
        "\n",
        "# --- 0. DRIVE & PATH SETUP ---\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "GDRIVE_ROOT = '/content/drive/MyDrive/'\n",
        "PROJECT_DIR = os.path.join(GDRIVE_ROOT, 'Deep Learning')\n",
        "MODELS_DIR = os.path.join(PROJECT_DIR, 'models', 'base_models')\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# --- 1. SEED SETUP ---\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "# --- 2. HARDWARE DETECTION (TUNED FOR A100) ---\n",
        "def get_optimal_config():\n",
        "    cpu_count = os.cpu_count()\n",
        "    optimal_workers = min(cpu_count, 8)\n",
        "    device_name = \"CPU\"\n",
        "    batch_size = 16\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        device_name = gpu_name\n",
        "        # --- TUNING ---\n",
        "        if \"A100\" in gpu_name:\n",
        "            batch_size = 512  # <--- Aggressiver für A100 (40GB VRAM erlaubt das locker)\n",
        "        elif \"T4\" in gpu_name:\n",
        "            batch_size = 128\n",
        "        else:\n",
        "            batch_size = 64\n",
        "    else:\n",
        "        print(\"WARNING: No GPU detected!\")\n",
        "\n",
        "    return device_name, batch_size, optimal_workers\n",
        "\n",
        "detected_device, auto_bs, auto_workers = get_optimal_config()\n",
        "\n",
        "# --- 3. CONFIGURATION ---\n",
        "CONFIG = {\n",
        "    'ARCH': 'resnet34',\n",
        "\n",
        "    # --- CONTROL CENTER ---\n",
        "    'DRY_RUN': False,            # <--- REAL TRAINING\n",
        "    'NUM_EPOCHS': 20,\n",
        "    # ----------------------\n",
        "\n",
        "    'BATCH_SIZE': auto_bs,\n",
        "    'NUM_WORKERS': auto_workers,\n",
        "    'DEVICE_NAME': detected_device,\n",
        "    'LEARNING_RATE': 1e-3,\n",
        "    'PATIENCE': 5,\n",
        "    'SUBSETS': [0.25, 0.50, 1.0],\n",
        "\n",
        "    'CHECKPOINT_DIR_LOC': '/content/checkpoints',\n",
        "    'CHECKPOINT_DIR_DRIVE': MODELS_DIR\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG['CHECKPOINT_DIR_LOC'], exist_ok=True)\n",
        "\n",
        "print(f\"\\nSystem Configuration:\")\n",
        "print(f\" -> Hardware:    {CONFIG['DEVICE_NAME']}\")\n",
        "print(f\" -> Batch Size:  {CONFIG['BATCH_SIZE']} (Optimized)\")\n",
        "print(f\" -> Workers:     {CONFIG['NUM_WORKERS']}\")\n",
        "print(f\" -> Mode:        {'DRY RUN' if CONFIG['DRY_RUN'] else 'REAL TRAINING'}\")\n",
        "\n",
        "# --- 4. MEMORY CLEANUP HELPER (NEW) ---\n",
        "def cleanup_memory():\n",
        "    \"\"\"Forces Garbage Collection and clears GPU Cache.\"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    # Optional: Print stats to verify\n",
        "    # print(f\"   [Mem] Reserved: {torch.cuda.memory_reserved(0)/1e9:.2f} GB\")\n",
        "\n",
        "\n",
        "# --- 5. MODEL FACTORY ---\n",
        "def get_base_model(arch_name, num_classes, pretrained=True):\n",
        "    # Loading logic same as before\n",
        "    if arch_name == 'resnet34':\n",
        "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT if pretrained else None)\n",
        "        in_features = model.fc.in_features\n",
        "    elif arch_name == 'resnet18':\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n",
        "        in_features = model.fc.in_features\n",
        "    elif arch_name == 'resnet50':\n",
        "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT if pretrained else None)\n",
        "        in_features = model.fc.in_features\n",
        "    else:\n",
        "        raise ValueError(\"Arch not supported\")\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# --- 6. DATA LOADER HELPER ---\n",
        "def get_subset_loader(fraction):\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    full_ds = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split='c_base', transform=train_transforms)\n",
        "\n",
        "    total_base_classes = len(full_ds.allowed_ids)\n",
        "    target_num = int(total_base_classes * fraction)\n",
        "    subset_ids = full_ds.allowed_ids[:target_num]\n",
        "\n",
        "    # Filter samples (Memory efficient filtering logic)\n",
        "    # We recreate the list to drop references to unused samples\n",
        "    new_samples = [s for s in full_ds.samples if s['label'] < target_num]\n",
        "    full_ds.samples = new_samples\n",
        "    full_ds.allowed_ids = subset_ids\n",
        "    full_ds.label_map = {orig: new for new, orig in enumerate(subset_ids)}\n",
        "\n",
        "    print(f\"\\n[Data] Subset {fraction*100}%: {len(new_samples)} images, {target_num} classes.\")\n",
        "\n",
        "    num_val = int(0.1 * len(full_ds))\n",
        "    train_ds, val_ds = random_split(full_ds, [len(full_ds)-num_val, num_val],\n",
        "                                    generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=True,\n",
        "                              num_workers=CONFIG['NUM_WORKERS'], pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=False,\n",
        "                            num_workers=CONFIG['NUM_WORKERS'], pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, target_num\n",
        "\n",
        "# --- 7. ROBUST CHECKPOINTING ---\n",
        "def safe_copy_to_drive(local_path, filename, max_retries=5):\n",
        "    drive_path = os.path.join(CONFIG['CHECKPOINT_DIR_DRIVE'], filename)\n",
        "    if not os.path.exists(CONFIG['CHECKPOINT_DIR_DRIVE']):\n",
        "        try: os.makedirs(CONFIG['CHECKPOINT_DIR_DRIVE'], exist_ok=True)\n",
        "        except: pass\n",
        "\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            shutil.copy(local_path, drive_path)\n",
        "            if os.path.exists(drive_path) and os.path.getsize(drive_path) > 0:\n",
        "                print(f\"   -> Drive Copy: SUCCESS\")\n",
        "                return\n",
        "        except Exception as e:\n",
        "            wait_time = 3 * attempt\n",
        "            print(f\"   [Retry {attempt}] Copy failed ({e}). Waiting {wait_time}s...\")\n",
        "            time.sleep(wait_time)\n",
        "    print(f\"   [CRITICAL ERROR] Failed to copy {filename} to Drive.\")\n",
        "\n",
        "def save_checkpoint(state, filename):\n",
        "    local_path = os.path.join(CONFIG['CHECKPOINT_DIR_LOC'], filename)\n",
        "    torch.save(state, local_path)\n",
        "    safe_copy_to_drive(local_path, filename)\n",
        "\n",
        "def save_best_model(model, filename):\n",
        "    local_path = os.path.join(CONFIG['CHECKPOINT_DIR_LOC'], filename)\n",
        "    torch.save(model.state_dict(), local_path)\n",
        "    safe_copy_to_drive(local_path, filename)\n",
        "\n",
        "# --- 8. TRAINING ENGINE ---\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, target_epochs, model_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    run_tag = \"_dryrun\" if CONFIG['DRY_RUN'] else \"\"\n",
        "    ckpt_filename = f\"{model_name}{run_tag}_checkpoint.pth\"\n",
        "    best_filename = f\"{model_name}{run_tag}_best.pth\"\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_acc = -1.0\n",
        "\n",
        "    # Resume Logic\n",
        "    drive_ckpt_path = os.path.join(CONFIG['CHECKPOINT_DIR_DRIVE'], ckpt_filename)\n",
        "    if os.path.exists(drive_ckpt_path):\n",
        "        print(f\"\\n[RESUME] Found: {ckpt_filename}\")\n",
        "        try:\n",
        "            checkpoint = torch.load(drive_ckpt_path, map_location=device)\n",
        "            saved_epoch = checkpoint['epoch']\n",
        "\n",
        "            if CONFIG['DRY_RUN']:\n",
        "                print(f\"   -> (Dry Run) Resetting loop despite found epoch {saved_epoch+1}.\")\n",
        "                start_epoch = 0\n",
        "                best_acc = checkpoint.get('best_acc', -1.0)\n",
        "            else:\n",
        "                if saved_epoch >= (target_epochs - 1):\n",
        "                    print(f\"   -> Fully trained ({saved_epoch+1} epochs). Skipping.\")\n",
        "                    return model\n",
        "                start_epoch = saved_epoch + 1\n",
        "                best_acc = checkpoint.get('best_acc', 0.0)\n",
        "\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            if 'scaler_state_dict' in checkpoint:\n",
        "                scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "            print(f\"   -> Resuming with Best Acc: {best_acc:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   [ERROR] Checkpoint corrupted ({e}). Fresh start.\")\n",
        "    else:\n",
        "        print(f\"\\n[START] Fresh start for {model_name}.\")\n",
        "\n",
        "    effective_epochs = 2 if CONFIG['DRY_RUN'] else target_epochs\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(start_epoch, effective_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{effective_epochs}\")\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        limit_batches = 5 if CONFIG['DRY_RUN'] else None\n",
        "\n",
        "        pbar = tqdm(train_loader, leave=False, desc=\"Training\")\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(pbar):\n",
        "            if limit_batches and i >= limit_batches: break\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "        iter_size = (limit_batches * CONFIG['BATCH_SIZE']) if limit_batches else len(train_loader.dataset)\n",
        "        if iter_size == 0: iter_size = 1\n",
        "        epoch_acc = running_corrects.double() / iter_size\n",
        "        epoch_loss = running_loss / iter_size\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_corrects = 0\n",
        "        val_limit = 5 if CONFIG['DRY_RUN'] else None\n",
        "        val_count = 0\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            if val_limit and i >= val_limit: break\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "            val_count += inputs.size(0)\n",
        "        val_acc = val_corrects.double() / val_count if val_count > 0 else 0.0\n",
        "        print(f\"   Train Acc: {epoch_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save Checkpoint\n",
        "        full_state = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'scaler_state_dict': scaler.state_dict(),\n",
        "            'best_acc': best_acc\n",
        "        }\n",
        "        save_checkpoint(full_state, ckpt_filename)\n",
        "\n",
        "        # Save Best Model logic\n",
        "        save_condition = False\n",
        "        if val_acc > best_acc: save_condition = True\n",
        "        elif CONFIG['DRY_RUN'] and val_acc >= best_acc: save_condition = True\n",
        "        elif best_acc == -1.0: save_condition = True\n",
        "\n",
        "        if save_condition:\n",
        "            best_acc = val_acc\n",
        "            save_best_model(model, best_filename)\n",
        "            print(f\"   [New Best] Saved {best_filename}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if not CONFIG['DRY_RUN'] and patience_counter >= CONFIG['PATIENCE']:\n",
        "            print(f\"   [Early Stopping] Reached patience limit.\")\n",
        "            break\n",
        "\n",
        "    print(f\"Training Finished. Final Best Acc: {best_acc:.4f}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# --- 9. EXECUTION LOOP (WITH CLEANUP) ---\n",
        "for fraction in CONFIG['SUBSETS']:\n",
        "    subset_name = f\"M_base_{int(fraction*100)}\"\n",
        "    print(f\"\\n{'='*40}\\nRUN: {subset_name}\\n{'='*40}\")\n",
        "\n",
        "    train_dl, val_dl, num_cls = get_subset_loader(fraction)\n",
        "    model = get_base_model(CONFIG['ARCH'], num_classes=num_cls)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['LEARNING_RATE'])\n",
        "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "    # Train\n",
        "    train_model(model, train_dl, val_dl, criterion, optimizer, lr_scheduler, CONFIG['NUM_EPOCHS'], subset_name)\n",
        "\n",
        "    # --- MEMORY CLEANUP ---\n",
        "    print(f\"   [Cleanup] Clearing GPU memory after {subset_name}...\")\n",
        "    del model\n",
        "    del optimizer\n",
        "    del criterion\n",
        "    del train_dl\n",
        "    del val_dl\n",
        "    cleanup_memory() # Call helper to force GC and Empty Cache\n",
        "    print(f\"   [Cleanup] Done. Ready for next model.\\n\")\n",
        "\n",
        "print(\"\\nPHASE 4 COMPLETE.\")"
      ],
      "metadata": {
        "id": "BbiMjGzgloUw"
      },
      "id": "BbiMjGzgloUw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Pfad anpassen falls nötig\n",
        "GDRIVE_ROOT = '/content/drive/MyDrive/'\n",
        "MODELS_DIR = os.path.join(GDRIVE_ROOT, 'Deep Learning', 'models', 'base_models')\n",
        "\n",
        "print(f\"Lese Ergebnisse aus: {MODELS_DIR}\\n\")\n",
        "\n",
        "subsets = [25, 50, 100]\n",
        "\n",
        "for s in subsets:\n",
        "    # Wir suchen nach der _checkpoint Datei, da diese die Metadaten hat\n",
        "    filename = f\"M_base_{s}_checkpoint.pth\"\n",
        "    path = os.path.join(MODELS_DIR, filename)\n",
        "\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            # Wir laden auf CPU, das geht schneller\n",
        "            checkpoint = torch.load(path, map_location='cpu')\n",
        "\n",
        "            acc = checkpoint.get('best_acc', -1)\n",
        "            epoch = checkpoint.get('epoch', -1)\n",
        "\n",
        "            print(f\"Modell {s}%:\")\n",
        "            print(f\"  -> Best Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "            print(f\"  -> Gestoppt nach Epoche: {epoch+1}\")\n",
        "            print(\"-\" * 30)\n",
        "        except Exception as e:\n",
        "            print(f\"Fehler beim Lesen von {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"WARNUNG: Checkpoint {filename} nicht gefunden. Nur _best.pth vorhanden?\")"
      ],
      "metadata": {
        "id": "XtyyskInML8W"
      },
      "id": "XtyyskInML8W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  PHASE 5: MAML \"PRO EDITION\" (AdamW, Clipping, 128px)\n",
        "#################################################################\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision import models, transforms\n",
        "\n",
        "print(\"\\n--- PHASE 5: Pipeline 1 - Meta-Learning (Pro Edition) ---\")\n",
        "\n",
        "# --- 0. SETUP ---\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "GDRIVE_ROOT = '/content/drive/MyDrive/'\n",
        "PROJECT_DIR = os.path.join(GDRIVE_ROOT, 'Deep Learning')\n",
        "BASE_MODELS_DIR = os.path.join(PROJECT_DIR, 'models', 'base_models')\n",
        "MAML_MODELS_DIR = os.path.join(PROJECT_DIR, 'models', 'maml_models')\n",
        "CHECKPOINT_DIR_LOC = '/content/checkpoints'\n",
        "\n",
        "os.makedirs(MAML_MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR_LOC, exist_ok=True)\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "MAML_CONFIG = {\n",
        "    'ARCH': 'resnet34',\n",
        "\n",
        "    # --- CONTROL CENTER ---\n",
        "    'DRY_RUN': False,            # <--- READY FOR REAL RUN\n",
        "    'META_ITERATIONS': 3000,     # 3k Iterations sind solide\n",
        "    'VAL_INTERVAL': 100,\n",
        "\n",
        "    # --- A100 TUNING FOR 128px ---\n",
        "    # Da 128px mehr Speicher braucht als 84px, gehen wir auf 16 Tasks runter.\n",
        "    # Das ist sicherer gegen OOM (Out of Memory).\n",
        "    'META_BATCH_SIZE': 16,\n",
        "    'IMG_SIZE': 128,             # <--- UPGRADE: Mehr Details für iNaturalist\n",
        "    # -----------------------------\n",
        "\n",
        "    # --- YOUR TUNED WINNERS (Run 3) ---\n",
        "    'META_LR': 0.001,\n",
        "    'INNER_LR': 0.01,\n",
        "    'INNER_STEPS': 5,\n",
        "\n",
        "    # --- NEW OPTIMIZER SETTINGS ---\n",
        "    'WEIGHT_DECAY': 1e-4,        # Für AdamW\n",
        "    'GRAD_CLIP': 1.0,            # Max Norm für Gradient Clipping\n",
        "\n",
        "    # Fixed Params\n",
        "    'WAYS': 5,\n",
        "    'SHOTS': 5,\n",
        "    'QUERY_SHOTS': 15,\n",
        "    'SUBSETS': [0.25, 0.50, 1.0]\n",
        "}\n",
        "\n",
        "if MAML_CONFIG['DRY_RUN']:\n",
        "    MAML_CONFIG['META_ITERATIONS'] = 5\n",
        "    MAML_CONFIG['VAL_INTERVAL'] = 1\n",
        "    MAML_CONFIG['META_BATCH_SIZE'] = 2\n",
        "\n",
        "print(f\"Config: {MAML_CONFIG['META_ITERATIONS']} Iters | Batch {MAML_CONFIG['META_BATCH_SIZE']} | Res {MAML_CONFIG['IMG_SIZE']}px\")\n",
        "print(f\"Params: MetaLR={MAML_CONFIG['META_LR']} | InnerLR={MAML_CONFIG['INNER_LR']} | Steps={MAML_CONFIG['INNER_STEPS']}\")\n",
        "print(f\"Extras: AdamW (WD={MAML_CONFIG['WEIGHT_DECAY']}) | GradClip={MAML_CONFIG['GRAD_CLIP']}\")\n",
        "\n",
        "\n",
        "# --- 2. OPTIMIZED DATA GENERATOR ---\n",
        "class A100TaskGenerator:\n",
        "    def __init__(self, dataset, ways, shots, query_shots):\n",
        "        self.dataset = dataset\n",
        "        self.ways = ways\n",
        "        self.shots = shots\n",
        "        self.query_shots = query_shots\n",
        "        self.indices_by_label = {}\n",
        "        for idx, sample in enumerate(dataset.samples):\n",
        "            lbl = sample['label']\n",
        "            if lbl not in self.indices_by_label: self.indices_by_label[lbl] = []\n",
        "            self.indices_by_label[lbl].append(idx)\n",
        "        self.classes = list(self.indices_by_label.keys())\n",
        "\n",
        "    def sample_batch(self, batch_size=16):\n",
        "        all_data = []\n",
        "        all_labels = []\n",
        "        for _ in range(batch_size):\n",
        "            selected_classes = random.sample(self.classes, self.ways)\n",
        "            task_imgs, task_lbls = [], []\n",
        "            for local_label, global_label in enumerate(selected_classes):\n",
        "                indices = self.indices_by_label[global_label]\n",
        "                needed = self.shots + self.query_shots\n",
        "                selected = random.sample(indices, needed) if len(indices) >= needed else random.choices(indices, k=needed)\n",
        "                for idx in selected:\n",
        "                    img, _ = self.dataset[idx]\n",
        "                    task_imgs.append(img)\n",
        "                    task_lbls.append(local_label)\n",
        "            all_data.append(torch.stack(task_imgs))\n",
        "            all_labels.append(torch.tensor(task_lbls))\n",
        "        return torch.stack(all_data), torch.stack(all_labels)\n",
        "\n",
        "def get_fast_taskset(split, ways=5, shots=5, query_shots=15):\n",
        "    NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
        "    NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "    # --- UPGRADE: 128px Resolution ---\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((MAML_CONFIG['IMG_SIZE'], MAML_CONFIG['IMG_SIZE'])),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "    ds = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=train_transforms)\n",
        "    return A100TaskGenerator(ds, ways, shots, query_shots)\n",
        "\n",
        "\n",
        "# --- 3. HELPERS: LOADING & SAVING ---\n",
        "def safe_copy_to_drive(local_path, filename):\n",
        "    drive_path = os.path.join(MAML_MODELS_DIR, filename)\n",
        "    try: shutil.copy(local_path, drive_path)\n",
        "    except Exception: pass\n",
        "\n",
        "def save_checkpoint(state, filename):\n",
        "    local_path = os.path.join(CHECKPOINT_DIR_LOC, filename)\n",
        "    torch.save(state, local_path)\n",
        "    safe_copy_to_drive(local_path, filename)\n",
        "\n",
        "def save_best_model(model_state, filename):\n",
        "    local_path = os.path.join(CHECKPOINT_DIR_LOC, filename)\n",
        "    torch.save(model_state, local_path)\n",
        "    safe_copy_to_drive(local_path, filename)\n",
        "    print(f\"   [New Best] Saved {filename}\")\n",
        "\n",
        "def load_base_model_for_maml(fraction, arch='resnet34'):\n",
        "    subset_name = f\"M_base_{int(fraction*100)}\"\n",
        "    candidates = [f\"{subset_name}_best.pth\", f\"{subset_name}_checkpoint.pth\", f\"{subset_name}_dryrun_best.pth\"]\n",
        "    path = None\n",
        "    for c in candidates:\n",
        "        p = os.path.join(BASE_MODELS_DIR, c)\n",
        "        if os.path.exists(p):\n",
        "            path = p\n",
        "            break\n",
        "    if path is None: raise FileNotFoundError(f\"No base model for {subset_name}\")\n",
        "\n",
        "    full_classes = 6000\n",
        "    num_classes = int(full_classes * fraction)\n",
        "    if arch == 'resnet34':\n",
        "        model = models.resnet34(weights=None)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    model.load_state_dict(torch.load(path, map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "\n",
        "# --- 4. MAML STEP (With Clipping) ---\n",
        "def optimized_maml_step(meta_model, tasks_data, tasks_labels, meta_optimizer, criterion, device, meta_batch_size):\n",
        "    meta_loss_total = 0.0\n",
        "    meta_optimizer.zero_grad()\n",
        "\n",
        "    ways, shots, queries = MAML_CONFIG['WAYS'], MAML_CONFIG['SHOTS'], MAML_CONFIG['QUERY_SHOTS']\n",
        "    support_indices, query_indices = [], []\n",
        "    for w in range(ways):\n",
        "        base = w * (shots + queries)\n",
        "        support_indices.extend(range(base, base + shots))\n",
        "        query_indices.extend(range(base + shots, base + shots + queries))\n",
        "\n",
        "    for i in range(meta_batch_size):\n",
        "        supp_X = tasks_data[i][support_indices]\n",
        "        supp_y = tasks_labels[i][support_indices]\n",
        "        query_X = tasks_data[i][query_indices]\n",
        "        query_y = tasks_labels[i][query_indices]\n",
        "\n",
        "        fast_model = copy.deepcopy(meta_model)\n",
        "        fast_model.train()\n",
        "        # Inner Loop uses SGD (Standard for MAML inner loop)\n",
        "        inner_opt = optim.SGD(fast_model.parameters(), lr=MAML_CONFIG['INNER_LR'])\n",
        "\n",
        "        for _ in range(MAML_CONFIG['INNER_STEPS']):\n",
        "            preds = fast_model(supp_X)\n",
        "            loss = criterion(preds, supp_y)\n",
        "            inner_opt.zero_grad()\n",
        "            loss.backward()\n",
        "            inner_opt.step()\n",
        "\n",
        "        q_preds = fast_model(query_X)\n",
        "        q_loss = criterion(q_preds, query_y)\n",
        "        meta_loss_total += q_loss.item()\n",
        "        q_loss.backward()\n",
        "\n",
        "        for mp, fp in zip(meta_model.parameters(), fast_model.parameters()):\n",
        "            if fp.grad is not None:\n",
        "                grad = fp.grad.detach() / meta_batch_size\n",
        "                if mp.grad is None: mp.grad = grad\n",
        "                else: mp.grad += grad\n",
        "\n",
        "        del fast_model, inner_opt\n",
        "\n",
        "    # --- UPGRADE: GRADIENT CLIPPING ---\n",
        "    # Prevents exploding gradients in the outer loop\n",
        "    torch.nn.utils.clip_grad_norm_(meta_model.parameters(), MAML_CONFIG['GRAD_CLIP'])\n",
        "\n",
        "    meta_optimizer.step()\n",
        "    return meta_loss_total / meta_batch_size\n",
        "\n",
        "\n",
        "# --- 5. VALIDATION STEP ---\n",
        "def evaluate_optimized(meta_model, val_generator, criterion, device):\n",
        "    meta_model.eval()\n",
        "    num_val_batches = 1 if MAML_CONFIG['DRY_RUN'] else 5\n",
        "    total_acc = 0.0\n",
        "    total_tasks = 0\n",
        "    meta_batch = MAML_CONFIG['META_BATCH_SIZE']\n",
        "\n",
        "    for _ in range(num_val_batches):\n",
        "        tasks_data, tasks_labels = val_generator.sample_batch(meta_batch)\n",
        "        tasks_data, tasks_labels = tasks_data.to(device), tasks_labels.to(device)\n",
        "\n",
        "        ways, shots, queries = MAML_CONFIG['WAYS'], MAML_CONFIG['SHOTS'], MAML_CONFIG['QUERY_SHOTS']\n",
        "        support_indices, query_indices = [], []\n",
        "        for w in range(ways):\n",
        "            base = w * (shots + queries)\n",
        "            support_indices.extend(range(base, base + shots))\n",
        "            query_indices.extend(range(base + shots, base + shots + queries))\n",
        "\n",
        "        batch_acc = 0.0\n",
        "        for i in range(meta_batch):\n",
        "            supp_X = tasks_data[i][support_indices]\n",
        "            supp_y = tasks_labels[i][support_indices]\n",
        "            query_X = tasks_data[i][query_indices]\n",
        "            query_y = tasks_labels[i][query_indices]\n",
        "\n",
        "            fast_model = copy.deepcopy(meta_model)\n",
        "            fast_model.train()\n",
        "            inner_opt = optim.SGD(fast_model.parameters(), lr=MAML_CONFIG['INNER_LR'])\n",
        "\n",
        "            for _ in range(MAML_CONFIG['INNER_STEPS']):\n",
        "                preds = fast_model(supp_X)\n",
        "                loss = criterion(preds, supp_y)\n",
        "                inner_opt.zero_grad()\n",
        "                loss.backward()\n",
        "                inner_opt.step()\n",
        "\n",
        "            fast_model.eval()\n",
        "            with torch.no_grad():\n",
        "                q_preds = fast_model(query_X)\n",
        "                _, predicted = torch.max(q_preds.data, 1)\n",
        "                batch_acc += (predicted == query_y).sum().item() / query_y.size(0)\n",
        "\n",
        "            del fast_model, inner_opt\n",
        "\n",
        "        total_acc += batch_acc\n",
        "        total_tasks += meta_batch\n",
        "\n",
        "    meta_model.train()\n",
        "    return total_acc / total_tasks\n",
        "\n",
        "\n",
        "# --- 6. MAIN TRAINING LOOP ---\n",
        "def run_maml_training(fraction):\n",
        "    maml_name = f\"M_maml_{int(fraction*100)}\"\n",
        "    run_tag = \"_dryrun\" if MAML_CONFIG['DRY_RUN'] else \"\"\n",
        "\n",
        "    ckpt_file = f\"{maml_name}{run_tag}_checkpoint.pth\"\n",
        "    best_file = f\"{maml_name}{run_tag}_best.pth\"\n",
        "\n",
        "    print(f\"\\n{'='*40}\\nMETA-TRAINING: {maml_name}{run_tag}\\n{'='*40}\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Generators (Note: IMG_SIZE is handled in get_fast_taskset)\n",
        "    train_gen = get_fast_taskset('c_base', MAML_CONFIG['WAYS'], MAML_CONFIG['SHOTS'], MAML_CONFIG['QUERY_SHOTS'])\n",
        "    val_gen = get_fast_taskset('c_val', MAML_CONFIG['WAYS'], MAML_CONFIG['SHOTS'], MAML_CONFIG['QUERY_SHOTS'])\n",
        "\n",
        "    meta_model = load_base_model_for_maml(fraction, MAML_CONFIG['ARCH'])\n",
        "    meta_model = meta_model.to(device)\n",
        "\n",
        "    # --- UPGRADE: ADAMW ---\n",
        "    meta_optimizer = optim.AdamW(meta_model.parameters(),\n",
        "                                 lr=MAML_CONFIG['META_LR'],\n",
        "                                 weight_decay=MAML_CONFIG['WEIGHT_DECAY'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    start_iter = 0\n",
        "    best_val_acc = -1.0\n",
        "\n",
        "    drive_ckpt_path = os.path.join(MAML_MODELS_DIR, ckpt_file)\n",
        "    if os.path.exists(drive_ckpt_path):\n",
        "        print(f\"[RESUME] Found {ckpt_file}\")\n",
        "        try:\n",
        "            ckpt = torch.load(drive_ckpt_path, map_location=device)\n",
        "            if MAML_CONFIG['DRY_RUN']:\n",
        "                 start_iter = 0\n",
        "                 best_val_acc = ckpt.get('best_val_acc', -1.0)\n",
        "            else:\n",
        "                 start_iter = ckpt['iteration'] + 1\n",
        "                 best_val_acc = ckpt.get('best_val_acc', 0.0)\n",
        "                 meta_model.load_state_dict(ckpt['model_state_dict'])\n",
        "                 meta_optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
        "                 print(f\"   -> Resuming from iter {start_iter} (Best Val Acc: {best_val_acc:.4f})\")\n",
        "        except Exception: pass\n",
        "\n",
        "    total_iters = 5 if MAML_CONFIG['DRY_RUN'] else MAML_CONFIG['META_ITERATIONS']\n",
        "    pbar = tqdm(range(start_iter, total_iters), desc=f\"{maml_name}\")\n",
        "\n",
        "    for i in pbar:\n",
        "        loss = optimized_maml_step(meta_model,\n",
        "                                   train_gen.sample_batch(MAML_CONFIG['META_BATCH_SIZE'])[0].to(device), # Hack to pass data\n",
        "                                   train_gen.sample_batch(MAML_CONFIG['META_BATCH_SIZE'])[1].to(device), # We need consistent data call\n",
        "                                   meta_optimizer, criterion, device, MAML_CONFIG['META_BATCH_SIZE'])\n",
        "\n",
        "        # Wait, calling sample_batch twice in argument is WRONG. They will be different random tasks!\n",
        "        # FIXING ON THE FLY BELOW:\n",
        "\n",
        "    # --- RESTARTING LOOP WITH CORRECT DATA FETCHING ---\n",
        "    for i in pbar:\n",
        "        # 1. Fetch Data Correctly\n",
        "        tasks_data, tasks_labels = train_gen.sample_batch(MAML_CONFIG['META_BATCH_SIZE'])\n",
        "        tasks_data, tasks_labels = tasks_data.to(device), tasks_labels.to(device)\n",
        "\n",
        "        # 2. Step\n",
        "        loss = optimized_maml_step(meta_model, tasks_data, tasks_labels, meta_optimizer, criterion, device, MAML_CONFIG['META_BATCH_SIZE'])\n",
        "        pbar.set_postfix(loss=f\"{loss:.4f}\")\n",
        "\n",
        "        # 3. Validation\n",
        "        if i % MAML_CONFIG['VAL_INTERVAL'] == 0 or i == total_iters - 1:\n",
        "            val_acc = evaluate_optimized(meta_model, val_gen, criterion, device)\n",
        "            tqdm.write(f\"   Iter {i}: Meta Loss {loss:.4f} | Val Acc {val_acc:.4f} (Best: {best_val_acc:.4f})\")\n",
        "\n",
        "            state = {\n",
        "                'iteration': i,\n",
        "                'model_state_dict': meta_model.state_dict(),\n",
        "                'optimizer_state_dict': meta_optimizer.state_dict(),\n",
        "                'best_val_acc': best_val_acc\n",
        "            }\n",
        "            save_checkpoint(state, ckpt_file)\n",
        "\n",
        "            save_condition = False\n",
        "            if val_acc > best_val_acc: save_condition = True\n",
        "            elif best_val_acc == -1.0: save_condition = True\n",
        "            elif MAML_CONFIG['DRY_RUN'] and val_acc >= best_val_acc: save_condition = True\n",
        "\n",
        "            if save_condition:\n",
        "                best_val_acc = val_acc\n",
        "                save_best_model(meta_model.state_dict(), best_file)\n",
        "\n",
        "    print(f\"Training Complete. Best Val Acc: {best_val_acc:.4f}\")\n",
        "    del meta_model, meta_optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# --- 7. EXECUTION ---\n",
        "if 'MetaINatDataset' not in globals(): raise NameError(\"Run Step 2.3 first!\")\n",
        "\n",
        "for fraction in MAML_CONFIG['SUBSETS']:\n",
        "    try:\n",
        "        run_maml_training(fraction)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {fraction}: {e}\")\n",
        "\n",
        "print(\"\\nPHASE 5 COMPLETE.\")"
      ],
      "metadata": {
        "id": "PLNuhzHGHswM"
      },
      "id": "PLNuhzHGHswM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################\n",
        "#  PHASE 5.2: HIGH-PERFORMANCE TUNING (A100 OPTIMIZED)\n",
        "#################################################################\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"\\n--- PHASE 5.2: High-Performance Tuning ---\")\n",
        "\n",
        "# --- 1. OPTIMIZED DATA GENERATOR ---\n",
        "# Wir erweitern den Generator, um 'Chunks' von Tasks zu liefern\n",
        "class A100TaskGenerator:\n",
        "    def __init__(self, dataset, ways, shots, query_shots):\n",
        "        self.dataset = dataset\n",
        "        self.ways = ways\n",
        "        self.shots = shots\n",
        "        self.query_shots = query_shots\n",
        "\n",
        "        # Caching indices for speed\n",
        "        self.indices_by_label = {}\n",
        "        for idx, sample in enumerate(dataset.samples):\n",
        "            lbl = sample['label']\n",
        "            if lbl not in self.indices_by_label: self.indices_by_label[lbl] = []\n",
        "            self.indices_by_label[lbl].append(idx)\n",
        "        self.classes = list(self.indices_by_label.keys())\n",
        "\n",
        "    def sample_batch(self, batch_size=32):\n",
        "        \"\"\"Generates a whole BATCH of tasks at once to minimize CPU overhead.\"\"\"\n",
        "        all_data = []\n",
        "        all_labels = []\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            selected_classes = random.sample(self.classes, self.ways)\n",
        "            task_imgs, task_lbls = [], []\n",
        "\n",
        "            for local_label, global_label in enumerate(selected_classes):\n",
        "                indices = self.indices_by_label[global_label]\n",
        "                needed = self.shots + self.query_shots\n",
        "                # Fast sampling\n",
        "                selected = random.sample(indices, needed) if len(indices) >= needed else random.choices(indices, k=needed)\n",
        "\n",
        "                for idx in selected:\n",
        "                    img, _ = self.dataset[idx]\n",
        "                    task_imgs.append(img)\n",
        "                    task_lbls.append(local_label)\n",
        "\n",
        "            # Stack images for this task: [N_Samples, C, H, W]\n",
        "            all_data.append(torch.stack(task_imgs))\n",
        "            all_labels.append(torch.tensor(task_lbls))\n",
        "\n",
        "        # Return stacked meta-batch: [MetaBatch, N_Samples, C, H, W]\n",
        "        return torch.stack(all_data), torch.stack(all_labels)\n",
        "\n",
        "# Wrapper to create the optimized generator\n",
        "def get_fast_taskset(split, ways=5, shots=5, query_shots=15):\n",
        "    # Re-use existing MetaINatDataset logic\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((84, 84)), # MAML standard size (faster)\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "    ])\n",
        "    ds = MetaINatDataset(DATASET_ROOT, PARTITION_FILE_PATH, split=split, transform=train_transforms)\n",
        "    return A100TaskGenerator(ds, ways, shots, query_shots)\n",
        "\n",
        "\n",
        "# --- 2. OPTIMIZED STEP FUNCTION ---\n",
        "def tuning_step_optimized(meta_model, task_generator, meta_optimizer, criterion, device, current_cfg, meta_batch_size):\n",
        "    meta_loss_total = 0.0\n",
        "    meta_optimizer.zero_grad()\n",
        "\n",
        "    # 1. FETCH ALL DATA AT ONCE (CPU -> GPU Transfer happens ONCE)\n",
        "    tasks_data, tasks_labels = task_generator.sample_batch(batch_size=meta_batch_size)\n",
        "    tasks_data, tasks_labels = tasks_data.to(device), tasks_labels.to(device)\n",
        "\n",
        "    # Pre-calculate indices\n",
        "    ways, shots, queries = 5, 5, 15\n",
        "    support_indices = []\n",
        "    query_indices = []\n",
        "    for w in range(ways):\n",
        "        base = w * (shots + queries)\n",
        "        support_indices.extend(range(base, base + shots))\n",
        "        query_indices.extend(range(base + shots, base + shots + queries))\n",
        "\n",
        "    # 2. LOOP ON GPU (No more CPU waiting)\n",
        "    for i in range(meta_batch_size):\n",
        "        # Slicing on GPU is fast\n",
        "        supp_X = tasks_data[i][support_indices]\n",
        "        supp_y = tasks_labels[i][support_indices]\n",
        "        query_X = tasks_data[i][query_indices]\n",
        "        query_y = tasks_labels[i][query_indices]\n",
        "\n",
        "        # --- Standard MAML Inner Loop ---\n",
        "        fast_model = copy.deepcopy(meta_model)\n",
        "        fast_model.train()\n",
        "        inner_opt = optim.SGD(fast_model.parameters(), lr=current_cfg['INNER_LR'])\n",
        "\n",
        "        for _ in range(current_cfg['INNER_STEPS']):\n",
        "            preds = fast_model(supp_X)\n",
        "            loss = criterion(preds, supp_y)\n",
        "            inner_opt.zero_grad()\n",
        "            loss.backward()\n",
        "            inner_opt.step()\n",
        "\n",
        "        q_preds = fast_model(query_X)\n",
        "        q_loss = criterion(q_preds, query_y)\n",
        "        meta_loss_total += q_loss.item()\n",
        "        q_loss.backward()\n",
        "\n",
        "        # Accumulate Gradients\n",
        "        for mp, fp in zip(meta_model.parameters(), fast_model.parameters()):\n",
        "            if fp.grad is not None:\n",
        "                grad = fp.grad.detach() / meta_batch_size\n",
        "                if mp.grad is None: mp.grad = grad\n",
        "                else: mp.grad += grad\n",
        "\n",
        "        del fast_model, inner_opt # Free VRAM immediately\n",
        "\n",
        "    meta_optimizer.step()\n",
        "    return meta_loss_total / meta_batch_size\n",
        "\n",
        "\n",
        "# --- 3. TUNING CONFIGURATION ---\n",
        "GRID_SEARCH = {\n",
        "    'META_LR': [1e-3, 1e-4],\n",
        "    'INNER_LR': [0.1, 0.01],\n",
        "    'INNER_STEPS': [1, 5]\n",
        "}\n",
        "\n",
        "TUNING_CONFIG = {\n",
        "    'ARCH': 'resnet34',\n",
        "    'SUBSET': 0.25,\n",
        "    'ITERS': 100,       # Weniger Iterationen, da Batch Size größer!\n",
        "    'META_BATCH': 32,   # <--- HIER IST DER TURBO! (Standard war 4)\n",
        "    'VAL_INT': 25,\n",
        "    'DRY_RUN': True\n",
        "}\n",
        "\n",
        "if TUNING_CONFIG['DRY_RUN']:\n",
        "    TUNING_CONFIG['ITERS'] = 2\n",
        "    TUNING_CONFIG['VAL_INT'] = 1\n",
        "    TUNING_CONFIG['META_BATCH'] = 2\n",
        "\n",
        "\n",
        "# --- 4. RUN ENGINE ---\n",
        "def run_tuning(combo_params):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    meta_model = load_base_model_for_maml(TUNING_CONFIG['SUBSET'], TUNING_CONFIG['ARCH'])\n",
        "    meta_model = meta_model.to(device)\n",
        "    meta_optimizer = optim.Adam(meta_model.parameters(), lr=combo_params['META_LR'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use optimized generator\n",
        "    train_gen = get_fast_taskset(split='c_base')\n",
        "    val_gen = get_fast_taskset(split='c_val') # Reuse for simplicity\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    pbar = tqdm(range(TUNING_CONFIG['ITERS']), desc=\"Run\", leave=False)\n",
        "    for i in pbar:\n",
        "        loss = tuning_step_optimized(meta_model, train_gen, meta_optimizer, criterion, device, combo_params, TUNING_CONFIG['META_BATCH'])\n",
        "        pbar.set_postfix(loss=f\"{loss:.3f}\")\n",
        "\n",
        "        if (i+1) % TUNING_CONFIG['VAL_INT'] == 0:\n",
        "            # Quick Validation (Zero-Shot Proxy for speed)\n",
        "            meta_model.eval()\n",
        "            correct, total = 0, 0\n",
        "            # Validate on 1 batch of tasks\n",
        "            v_data, v_lbl = val_gen.sample_batch(4)\n",
        "            v_data, v_lbl = v_data.to(device), v_lbl.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Flatten batch for simple forward pass check\n",
        "                B, N, C, H, W = v_data.shape\n",
        "                logits = meta_model(v_data.view(-1, C, H, W))\n",
        "                targets = v_lbl.view(-1)\n",
        "                _, preds = torch.max(logits, 1)\n",
        "                correct += (preds == targets).sum().item()\n",
        "                total += targets.size(0)\n",
        "            acc = correct / total\n",
        "            if acc > best_acc: best_acc = acc\n",
        "            meta_model.train()\n",
        "\n",
        "    return best_acc\n",
        "\n",
        "# --- 5. EXECUTION ---\n",
        "print(f\"Starting A100 Optimized Tuning (Batch Size {TUNING_CONFIG['META_BATCH']})...\")\n",
        "results = []\n",
        "keys = list(GRID_SEARCH.keys())\n",
        "combos = list(itertools.product(*GRID_SEARCH.values()))\n",
        "\n",
        "combo_pbar = tqdm(combos, desc=\"Total Progress\")\n",
        "for c in combo_pbar:\n",
        "    params = dict(zip(keys, c))\n",
        "    try:\n",
        "        score = run_tuning(params)\n",
        "        res = params.copy()\n",
        "        res['Acc'] = score\n",
        "        results.append(res)\n",
        "        combo_pbar.write(f\" -> {params} | Acc: {score:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# --- 6. RESULTS ---\n",
        "if results:\n",
        "    df = pd.DataFrame(results).sort_values(by='Acc', ascending=False)\n",
        "    print(\"\\n\", df)\n",
        "\n",
        "    # Heatmap logic\n",
        "    unique_steps = df['INNER_STEPS'].unique()\n",
        "    fig, axes = plt.subplots(1, len(unique_steps), figsize=(12, 5), sharey=True)\n",
        "    if len(unique_steps) == 1: axes = [axes]\n",
        "    for i, steps in enumerate(sorted(unique_steps)):\n",
        "        ax = axes[i]\n",
        "        subset = df[df['INNER_STEPS'] == steps]\n",
        "        pivot = subset.pivot(index='META_LR', columns='INNER_LR', values='Acc')\n",
        "        sns.heatmap(pivot, annot=True, fmt=\".4f\", cmap=\"viridis\", ax=ax)\n",
        "        ax.set_title(f\"Inner Steps: {steps}\")\n",
        "    plt.show()\n",
        "\n",
        "    win = df.iloc[0]\n",
        "    print(f\"\\nWINNER: MetaLR={win['META_LR']}, InnerLR={win['INNER_LR']}, Steps={int(win['INNER_STEPS'])}\")"
      ],
      "metadata": {
        "id": "W3hgf4PdMhLb"
      },
      "id": "W3hgf4PdMhLb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}